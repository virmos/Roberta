{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"RoBERTa.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"187ff8cf813f409383dc9419d289fb5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fa3b7f2511454424b2d1f50e5b193766","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3edb969a48064cfb9f72148f13ccca48","IPY_MODEL_b56e6541a1cc4873b50ea780a5802591","IPY_MODEL_220de73859004c788efc7c3f6ae6ffc0"]}},"fa3b7f2511454424b2d1f50e5b193766":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"3edb969a48064cfb9f72148f13ccca48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9fd708e08caa4f74ac4b6be6bc1bb82a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 0: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8d3a32d6768434988685192333ec147"}},"b56e6541a1cc4873b50ea780a5802591":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_634100632cf447b380c5f4186f782538","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_807a370805e140cdb04eee9f184de0da"}},"220de73859004c788efc7c3f6ae6ffc0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_073be319d4da4369916614eb9187dec3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:14&lt;00:00,  7.47s/it, loss=0.692, v_num=]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_492036cc591b447cb6b42b8a87c5c2aa"}},"9fd708e08caa4f74ac4b6be6bc1bb82a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b8d3a32d6768434988685192333ec147":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"634100632cf447b380c5f4186f782538":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"807a370805e140cdb04eee9f184de0da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"073be319d4da4369916614eb9187dec3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"492036cc591b447cb6b42b8a87c5c2aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"02b053738937420e92d609faeab512fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f67f4fb024e8443bbd3087a2ebbc5b61","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a923349caf2b47cf96acaf440c259041","IPY_MODEL_a621a93ceb0e4cebb69fa0cae10ec4eb","IPY_MODEL_580065394c3d4aedbd2003e05618f98c"]}},"f67f4fb024e8443bbd3087a2ebbc5b61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"a923349caf2b47cf96acaf440c259041":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dc27247c51994fcf9039b9a5cdbfeb7d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a585967c728748568fe269a7bc74d7b6"}},"a621a93ceb0e4cebb69fa0cae10ec4eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4f13b487b2c64fe99422d84cbea0f272","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_21dda556134d4c03a9cb7fa9f014632e"}},"580065394c3d4aedbd2003e05618f98c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8051f7a94d574c7da0823c200f38b225","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:03&lt;00:00,  3.64s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6845c913925d4d8594b15b463a5177a7"}},"dc27247c51994fcf9039b9a5cdbfeb7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a585967c728748568fe269a7bc74d7b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f13b487b2c64fe99422d84cbea0f272":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"21dda556134d4c03a9cb7fa9f014632e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8051f7a94d574c7da0823c200f38b225":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6845c913925d4d8594b15b463a5177a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5bfc7cb5bd645a1bc2e9313d2101dd2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3e973a04cd814ff18739a5fd8ddc699a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9e7d33b23f4d42eb93fe174cf2af3453","IPY_MODEL_8955877c902b44e9a35694fc2f234fbc","IPY_MODEL_8e76dd3f3ede4727ae082fb2e91c9948"]}},"3e973a04cd814ff18739a5fd8ddc699a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"9e7d33b23f4d42eb93fe174cf2af3453":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a60b8dd809b14a4d85ad41eaa91fb509","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validation sanity check:   0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d8ae352ea3384079a224d9c447b32431"}},"8955877c902b44e9a35694fc2f234fbc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2e8df380f56244178cf0ddc2dddc9f3b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_558d92c75cd64664890305c515e62389"}},"8e76dd3f3ede4727ae082fb2e91c9948":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4dfa97007ad840af8aead701031322c0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/2 [00:01&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f00847f053794341ac613797696c576b"}},"a60b8dd809b14a4d85ad41eaa91fb509":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d8ae352ea3384079a224d9c447b32431":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e8df380f56244178cf0ddc2dddc9f3b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"558d92c75cd64664890305c515e62389":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4dfa97007ad840af8aead701031322c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f00847f053794341ac613797696c576b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc51334b15514b02a15670f7befa7d56":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7e39d85b5f8c459ca5241bceca77fd66","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cd10c98aa74e49e0aa8aea58e87bc998","IPY_MODEL_ce3d4395812f446cb9f1bcd0ce6f769b","IPY_MODEL_ce5c6701885745bd9f7e0f5ff7d50994"]}},"7e39d85b5f8c459ca5241bceca77fd66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"cd10c98aa74e49e0aa8aea58e87bc998":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b7067c72d03748eb8e0ebfc7a2af82b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 3:  50%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4d0af1ee648146b4a69caf7a12ce1d0e"}},"ce3d4395812f446cb9f1bcd0ce6f769b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f4300b0c2f2d451ca17418cd4321d4b8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":2026,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1020,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3f07d82072c34fffb58cc514897d6d06"}},"ce5c6701885745bd9f7e0f5ff7d50994":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fd2226c561c94049bfe095a7fde810a7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1020/2026 [10:07&lt;09:59,  1.68it/s, loss=0.183, v_num=2]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69aaffdd11c045d188b208f2dc86bbe6"}},"b7067c72d03748eb8e0ebfc7a2af82b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4d0af1ee648146b4a69caf7a12ce1d0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f4300b0c2f2d451ca17418cd4321d4b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3f07d82072c34fffb58cc514897d6d06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd2226c561c94049bfe095a7fde810a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"69aaffdd11c045d188b208f2dc86bbe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1260c4a7d0fd40dabe89d2efd4b90924":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_636177abb60546f3921025b80ea37f06","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5787a3b635e54f12bab9efc3511f2dd4","IPY_MODEL_82210154e22647fc93138392f0a5a1a7","IPY_MODEL_0d18e1a3a5dc4988aed08b0324134641"]}},"636177abb60546f3921025b80ea37f06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"5787a3b635e54f12bab9efc3511f2dd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_11bfcdb589204efa92395ae4d452fdab","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1fdbe635aeb5406896312e1dec9e7174"}},"82210154e22647fc93138392f0a5a1a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bb3d74ec597e4e96a71a83417d8bf4b6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":338,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":338,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ab12e5d69eec466fa02758a51ca23f40"}},"0d18e1a3a5dc4988aed08b0324134641":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_43cd1fad28244a4ab675bc6e2a4cf708","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 338/338 [01:27&lt;00:00,  3.92it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ccd1d1dd6d1e46b2b99f143aae378847"}},"11bfcdb589204efa92395ae4d452fdab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1fdbe635aeb5406896312e1dec9e7174":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb3d74ec597e4e96a71a83417d8bf4b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ab12e5d69eec466fa02758a51ca23f40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"43cd1fad28244a4ab675bc6e2a4cf708":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ccd1d1dd6d1e46b2b99f143aae378847":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"065e68cad9854b348b67ef939d0bcafd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3428fe23f79244558619570a83099c59","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1db36b299f6940c1ad31fc109d5876cb","IPY_MODEL_d693547b0e614648b691af41bb160265","IPY_MODEL_474e2114c306478297fc756e1d51ad35"]}},"3428fe23f79244558619570a83099c59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"1db36b299f6940c1ad31fc109d5876cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2f7f8e5765444e4c833084897765c6cb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_25da9df499344d2bbf2d161f1e5e960e"}},"d693547b0e614648b691af41bb160265":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ee020b0333244c2290e441754bd083cb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":338,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":338,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4cb4f2ec10fa41e0a285b00c78461a34"}},"474e2114c306478297fc756e1d51ad35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d9a2f73080044233b71e76878354b370","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 338/338 [01:27&lt;00:00,  3.93it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_efad8ed4c356462992df6b0d5b61ea3d"}},"2f7f8e5765444e4c833084897765c6cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"25da9df499344d2bbf2d161f1e5e960e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee020b0333244c2290e441754bd083cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4cb4f2ec10fa41e0a285b00c78461a34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9a2f73080044233b71e76878354b370":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"efad8ed4c356462992df6b0d5b61ea3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c96502cbd8242099c7d4540a29099e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_124ae2fd6e994c69ac31fbc3b643bc77","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1512fa40d5284773aea5eb7870144f7f","IPY_MODEL_90707f73f2ea4e4b844d21def6b18a0c","IPY_MODEL_55bee780013041d88443cfddbc365e0f"]}},"124ae2fd6e994c69ac31fbc3b643bc77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"1512fa40d5284773aea5eb7870144f7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7dbfb7a63761415e819ae435a943c9bb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bbe639e8ce844ccbafe164ca0f6c07ef"}},"90707f73f2ea4e4b844d21def6b18a0c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0feeea6de748413db11852be28d9821f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":338,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":338,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc18deaa9b144218a191437b7739346c"}},"55bee780013041d88443cfddbc365e0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0ea8439ae165495783bb1e9a12c3ad7b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 338/338 [01:27&lt;00:00,  3.93it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bfd219e042e04de2898015d57f072e4b"}},"7dbfb7a63761415e819ae435a943c9bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bbe639e8ce844ccbafe164ca0f6c07ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0feeea6de748413db11852be28d9821f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bc18deaa9b144218a191437b7739346c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ea8439ae165495783bb1e9a12c3ad7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bfd219e042e04de2898015d57f072e4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"589ce4b9ec8a4832b0b23ee312fd6d90":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2c36f62e4b6446a4be77d2015231d899","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fa43ef9b22ff465188d5791fca172568","IPY_MODEL_435c2bac57b1467b92432f4b32669f71","IPY_MODEL_3b5426e1d8ee494dbeae33392de19f13"]}},"2c36f62e4b6446a4be77d2015231d899":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"fa43ef9b22ff465188d5791fca172568":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ae83e83933134135954fb22d890d963d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_500732b0428f4697903e44019f193e86"}},"435c2bac57b1467b92432f4b32669f71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f211e9d2a18949c1945d26d4a2a00d3f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":338,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":338,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89e6aa53170c426387e2548d4ca3a2bc"}},"3b5426e1d8ee494dbeae33392de19f13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bd1405cbed0b42d1bdab92ed1ff04c79","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 338/338 [01:27&lt;00:00,  3.93it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_daa7278e42fd4243972a11b368a940be"}},"ae83e83933134135954fb22d890d963d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"500732b0428f4697903e44019f193e86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f211e9d2a18949c1945d26d4a2a00d3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"89e6aa53170c426387e2548d4ca3a2bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd1405cbed0b42d1bdab92ed1ff04c79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"daa7278e42fd4243972a11b368a940be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5611a00c21a842d1b21e238f8aa2e495":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_afcbf53ffb2847ff8f2cd34648a3ba4d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8a0cf7c5e5c642a785d329e38875b8e7","IPY_MODEL_6e2e43ebb08844608a9a0a5645cc6cf4","IPY_MODEL_1073143fe61e4761a744d49a996b80d5"]}},"afcbf53ffb2847ff8f2cd34648a3ba4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"8a0cf7c5e5c642a785d329e38875b8e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_49a04245cb62432aac898d5c58153210","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f712795aaa614ef98355023f07cf204c"}},"6e2e43ebb08844608a9a0a5645cc6cf4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_684f762194a2418181e09ea7fef7d62a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":338,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":338,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e122750287945a8b895e9812075ce20"}},"1073143fe61e4761a744d49a996b80d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_61a0417cebfe4ef6b64caee15983209e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 338/338 [01:27&lt;00:00,  3.93it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dbd2681c21254b09bce79054a41a12ed"}},"49a04245cb62432aac898d5c58153210":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f712795aaa614ef98355023f07cf204c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"684f762194a2418181e09ea7fef7d62a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7e122750287945a8b895e9812075ce20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61a0417cebfe4ef6b64caee15983209e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dbd2681c21254b09bce79054a41a12ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4db087b10e049fbbc9436fabf77d37e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dd8a73c059e6428d80e0734b8a82aff4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_add6c226c5ee493293c17f58ceb14fd4","IPY_MODEL_fe181e62beb24f16ab54202c8a3e53cf","IPY_MODEL_17f9afed3f6c4fdbbfa25b00689cbcda"]}},"dd8a73c059e6428d80e0734b8a82aff4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"add6c226c5ee493293c17f58ceb14fd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d94ec2f07fbd4475a7054b07996abb6c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e71e6e50a66457e8c24f836127bef11"}},"fe181e62beb24f16ab54202c8a3e53cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b8ef787141c2487986a34aefe659a7d0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":338,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":338,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4c1d22e7b4cb4186a7fc26d0957370ba"}},"17f9afed3f6c4fdbbfa25b00689cbcda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_94ea8fc5fffe46e6b215e64da7abb4ea","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 338/338 [01:27&lt;00:00,  3.93it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4a456d587f6b4961aa4e448d402cab4f"}},"d94ec2f07fbd4475a7054b07996abb6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8e71e6e50a66457e8c24f836127bef11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8ef787141c2487986a34aefe659a7d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4c1d22e7b4cb4186a7fc26d0957370ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"94ea8fc5fffe46e6b215e64da7abb4ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4a456d587f6b4961aa4e448d402cab4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d39e21d88b364c0ea8b1ec86d7602527":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0fb031d06a6446fba8b897bb86b48fa4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_18350d4e2e414097bd87c466e1ac3f32","IPY_MODEL_1e6b9d6ac7e64e7ebc3189a0b71bcda6","IPY_MODEL_94aa377685624923a995e9fdab4612e8"]}},"0fb031d06a6446fba8b897bb86b48fa4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"18350d4e2e414097bd87c466e1ac3f32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_260121785a844a3282dad7cebaa7c75e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_23b582dca6794efab3fd0451abedb24a"}},"1e6b9d6ac7e64e7ebc3189a0b71bcda6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_59c1adbc66784a87b0071276d71466ed","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":338,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":338,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_27c1291be5d64d52b6cced79e3119965"}},"94aa377685624923a995e9fdab4612e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dc50a6ab1fba4917aa33aae4315eb4ba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 338/338 [01:27&lt;00:00,  3.93it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f93c76a5c1348e6ad8736bf391e5a05"}},"260121785a844a3282dad7cebaa7c75e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"23b582dca6794efab3fd0451abedb24a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"59c1adbc66784a87b0071276d71466ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"27c1291be5d64d52b6cced79e3119965":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc50a6ab1fba4917aa33aae4315eb4ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7f93c76a5c1348e6ad8736bf391e5a05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PCDyJwo0UnIk","executionInfo":{"status":"ok","timestamp":1636626135814,"user_tz":-420,"elapsed":333,"user":{"displayName":"19021256 Hà Đông Giang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gja8sSUuDXalRZWbplQyuJDwBAfSe11LPI2D-Ebjw=s64","userId":"04530108174427629943"}},"outputId":"8100b956-cfbe-43ac-bfc2-0f370d5cb53e"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9uVlPq0rUeIO","executionInfo":{"status":"ok","timestamp":1636626229297,"user_tz":-420,"elapsed":93152,"user":{"displayName":"19021256 Hà Đông Giang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gja8sSUuDXalRZWbplQyuJDwBAfSe11LPI2D-Ebjw=s64","userId":"04530108174427629943"}},"outputId":"4166ace3-2240-4ef0-a4a8-7d4b71057ffc"},"source":["# !pip install --upgrade torch==1.5.0\n","!pip install fairseq==0.9.0\n","!pip install pytorch-lightning\n","!pip install transformers\n","!pip install sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fairseq==0.9.0\n","  Downloading fairseq-0.9.0.tar.gz (306 kB)\n","\u001b[K     |████████████████████████████████| 306 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==0.9.0) (1.15.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==0.9.0) (0.29.24)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==0.9.0) (1.19.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==0.9.0) (2019.12.20)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 8.8 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==0.9.0) (1.9.0+cu111)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==0.9.0) (4.62.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==0.9.0) (2.20)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->fairseq==0.9.0) (0.8.9)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq==0.9.0) (3.10.0.2)\n","Building wheels for collected packages: fairseq\n","  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.9.0-cp37-cp37m-linux_x86_64.whl size=2155897 sha256=b595a52aa41ef33dc4e5e50810696e141be7c2aa9d1f9fa04144df3d135e5448\n","  Stored in directory: /root/.cache/pip/wheels/6b/27/e2/c55614da7eb71041bb08f02e8a302b869e51185eb7c575a604\n","Successfully built fairseq\n","Installing collected packages: portalocker, colorama, sacrebleu, fairseq\n","Successfully installed colorama-0.4.4 fairseq-0.9.0 portalocker-2.3.2 sacrebleu-2.0.0\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.5.1-py3-none-any.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 5.2 MB/s \n","\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 47.6 MB/s \n","\u001b[?25hCollecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 36.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.10.0.2)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.7.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.2)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.9.0+cu111)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.62.3)\n","Collecting PyYAML>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 46.8 MB/s \n","\u001b[?25hCollecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n","\u001b[K     |████████████████████████████████| 329 kB 49.8 MB/s \n","\u001b[?25hCollecting pyDeprecate==0.3.1\n","  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 44.2 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (2.4.7)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.41.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 48.3 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.7)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 47.6 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.2.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n","\u001b[K     |████████████████████████████████| 192 kB 51.7 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.6.0)\n","Building wheels for collected packages: future\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=301949baecec6f3e161127ca4c9f405f8b06a3c6269e7ab0c43245c64392d1bc\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","Successfully built future\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, future, pytorch-lightning\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","Successfully installed PyYAML-6.0 aiohttp-3.8.0 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 frozenlist-1.2.0 fsspec-2021.11.0 future-0.18.2 multidict-5.2.0 pyDeprecate-0.3.1 pytorch-lightning-1.5.1 torchmetrics-0.6.0 yarl-1.7.2\n","Collecting transformers\n","  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 43.7 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 6.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 37.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.1.2 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.3\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}]},{"cell_type":"markdown","metadata":{"id":"ObVSjGJ2Adwi"},"source":["# LOAD DATA"]},{"cell_type":"code","metadata":{"id":"C5tPeRinVUmh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636626230066,"user_tz":-420,"elapsed":780,"user":{"displayName":"19021256 Hà Đông Giang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gja8sSUuDXalRZWbplQyuJDwBAfSe11LPI2D-Ebjw=s64","userId":"04530108174427629943"}},"outputId":"565a3689-cc75-4cb1-b75d-5f6867e0e462"},"source":["DATA_ROOT_DIR=\"/content/drive/MyDrive/programming/nlp/dataset/shopee-sentiment\"\n","!ls $DATA_ROOT_DIR"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_submission.csv  train.csv\t\t       train.xlsx\n","test.csv\t       train_preprocess.csv\n","test_preprocess.csv    train_preprocess_unsegment.csv\n"]}]},{"cell_type":"code","metadata":{"id":"T-95Em2MAchd"},"source":["import pandas as pd\n","import numpy as np\n","from torch.utils.data import random_split, DataLoader, Dataset\n","import pytorch_lightning as pl\n","import torch.nn as nn\n","import torch\n","\n","train_ratio = 0.8\n","DATA_DIR = DATA_ROOT_DIR + '/train_preprocess_unsegment.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pk6fOTGRhDUb","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1636626235725,"user_tz":-420,"elapsed":1536,"user":{"displayName":"19021256 Hà Đông Giang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gja8sSUuDXalRZWbplQyuJDwBAfSe11LPI2D-Ebjw=s64","userId":"04530108174427629943"}},"outputId":"85189fd4-b548-4dca-a06f-f2dc2a82a807"},"source":["train = pd.read_csv(DATA_DIR, index_col=0)\n","train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>class</th>\n","      <th>preprocess_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>dee6dfc5</td>\n","      <td>Đến quán 2 lần thôi , rất là thích !\\nQuán tuy...</td>\n","      <td>1</td>\n","      <td>đến quán 2 lần thôi rất là thích quán tuy nằm ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>800813f5</td>\n","      <td>Đến quán vào tối chủ_nhật . Có band hát . Khá ...</td>\n","      <td>0</td>\n","      <td>đến quán vào tối chủ nhật có band hát khá ổn t...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6553e47f</td>\n","      <td>Phục_vụ lâu quá mặc_dù khách rất vắng .\\nĐợi g...</td>\n","      <td>0</td>\n","      <td>phục vụ lâu quá mặc dù khách rất vắng đợi gần ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>b45a1ff1</td>\n","      <td>Ko gian bé_tí , quán chật_chội , đông người nê...</td>\n","      <td>0</td>\n","      <td>ko gian bé tí   quán chật chội đông người nên ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>f92694b0</td>\n","      <td>Khi mình order , đặt bánh thì nhận được sự tiế...</td>\n","      <td>1</td>\n","      <td>khi mình order đặt bánh thì nhận được sự tiếp ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id  ...                                    preprocess_text\n","0  dee6dfc5  ...  đến quán 2 lần thôi rất là thích quán tuy nằm ...\n","1  800813f5  ...  đến quán vào tối chủ nhật có band hát khá ổn t...\n","2  6553e47f  ...  phục vụ lâu quá mặc dù khách rất vắng đợi gần ...\n","3  b45a1ff1  ...  ko gian bé tí   quán chật chội đông người nên ...\n","4  f92694b0  ...  khi mình order đặt bánh thì nhận được sự tiếp ...\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"PzegOvuxhla8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636626236606,"user_tz":-420,"elapsed":890,"user":{"displayName":"19021256 Hà Đông Giang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gja8sSUuDXalRZWbplQyuJDwBAfSe11LPI2D-Ebjw=s64","userId":"04530108174427629943"}},"outputId":"9bd0c991-1dda-47a0-9a0e-3dc870f95050"},"source":["from typing import *\n","\n","class SentimentData(Dataset):\n","  def __init__(self, data_dir):\n","    self.df = pd.read_csv(data_dir, index_col=0)\n","\n","  def __len__(self):\n","    return len(self.df)\n","\n","  def __getitem__(self, idx):\n","    text = self.df[\"preprocess_text\"][idx]\n","    label = self.df[\"class\"][idx]\n","    \n","    return text, label\n","\n","class SentimentDataModule(pl.LightningDataModule):\n","\n","    def __init__(self, data_dir: str = DATA_DIR, batch_size: int = 16):\n","        super().__init__()\n","        self.data_dir = data_dir\n","        self.batch_size = batch_size\n","\n","    def setup(self, stage: Optional[str] = None):\n","        data_full = SentimentData(self.data_dir)\n","        train_size = round(len(data_full)*train_ratio)\n","        val_size = len(data_full) - train_size\n","        print(len(data_full), train_size, val_size)\n","        self.data_train, self.data_val = random_split(data_full, [train_size, val_size])\n","\n","    def train_dataloader(self):\n","        return DataLoader(self.data_train, batch_size=self.batch_size)\n","\n","    def val_dataloader(self):\n","        return DataLoader(self.data_val, batch_size=self.batch_size)\n","\n","\n","if __name__ == \"__main__\":\n","\tdm = SentimentDataModule(DATA_DIR)\n","\tdm.setup()\n","\tidx = 0\n","\tfor item in (dm.train_dataloader()):\n","\t\tprint(idx)\n","\t\tprint(item)\n","\t\tidx += 1\n","\t\tif idx > 5: break"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27000 21600 5400\n","0\n","[('hôm nay ghé lại urban có thấy ra mắt 3 món mới về trà ấn tượng đầu tiên là mấy cái tên twilight lorax đồ cơ mà ngon lạ hợp với thời tiết hiện nay có điều hút mấy cái thạch trong ly lên khó quá có một món nóng nhưng chưa thử lần sau nhất định sẽ ghé lại d', 'là 1 nơi yên tĩnh và lịch sự rất hợp với cặp đôi hẹn hò hay canh chị em tâm sự họp nhóm đông thì có vẻ khôg hợp lắm vì không gian kín làm ồn kì lắm li socola đá say giá 48 rất ngon nhưng hơi ngọt nếu không thích uống ngọt nên kêu cho ít đường nha', 'helo san fu lou   mình muốn complain về nhân viên host waiter của nhà hàng mình không nói tên nhân viên vì chỉ muốn góp ý tối nay mình đi ăn với bạn gái nhà hàng còn khá nhiều chỗ nhưng đã có khách đặt còn cả tiếng đồng hồ nữa khách mới đến mình có nói rõ vs nhân viên host là mình chỉ ăn tối nhanh rồi đi vậy mà nhân viên host cứ từ chối rồi đổi chỗ ngồi lung tung sau khi mình order 2 món mới ăn được 25 trong khi vẫn còn 57 bàn trống mình tính gọi thêm món nhưng phục vụ lại nhắc thẳng mặt mình là có nhiều khách sắp đến xin mình ăn nhanh lên nên mình cảm thấy rất bực bội làm mất hứng hết cả buổi ăn tối nên mình đành tính tiền để đi mong nhà hàng cải thiện thái độ phục vụ của nhân viên cách sắp xếp host sao cho hợp lý', 'kem ngon ngon béo béo bé chủ dễ thương khách chờ lâu được tặng 1ly trà chanh ngoài ra khách còn được tự tay làm kem nữa trà sữa thái thì tuyệt vời các loại soda siêu đẹp vị ngon và lạ nói chung là rất ok quán làm theo dạng take away nhưng vẫn có ghế cho khách chờ kem', 'địa điểm hợp lý để xem bóng đá màn hình lớn giá rẻ chỗ đậu xe rộng rãi mỗi tội buổi tối thì có muỗi', 'nghe qua bufet hana đã lâu ghé thử thì monhf cảm thấy không được tuyệt vời như mình mong đợi cho lắm mới vô là phải chạy ra trường tiểu học gần đó gửi xe cảm giác đã có cái j đó sai sai vô ngồi bàn thì menu rất hấp dẫn do mình đi hai người nên có dặn qua dặn lại nhân viên đồ ăn lên ít hơn đĩa bình thường vì nhiều quá ăn không hết sẽ phí sau khi gọi đồ ăn hết một vòng thì một số món khai vị đã hết chỉ còn một số món mà mình không thích lấy nên chỉ lấy món rong biển chiên nhân viên lấy ra một đĩa đầy ắp cac món salad nhìn trên menu khá chuyên nghiệp mình thử món salad cá ngừ cá hồi khá lạ hải sản tương sống đem lên rất tuyệt vời hàu tươi rất tươi ăn sống hay nướng phô mai đều rất ngon sò điệp và tôm cũng khá ổn đến màn thịt thì hơi thất vọng thịt nhìn màu tái sậm như kiểu không tươi mà bao nhiêu món mình kêu dồn vô chung một dĩa một nhìn hỗn loạn và không biết món nào ra món nào thịt thì ăn được nhưng ngoại hình rất ảnh hưởng vị giác người ăn mà thịt như ướp không thấm lắm ăn có vị ướp nhẹ nhưng chưa tới món lẩu lên lúc cuối cũng tạm được có các loại mì đậu xanh mì trứng sẽ quay lại sau một thời gian để xem chất lượng có thay đổi không', 'có một thời gian trước đó mình rất hay lên đây ngồi có tuần ngồi 45 lần liền cứ lên phố là sẽ mặc định vào cofe house theo như mình biết thì đây là tiệm cofe house đầu tiên ở hà nội còn trong sài gòn chuỗi cofe house nổi tiếng rồi thì không nói hồi đầu mình hẹn bạn bè ra cofe house mọi người toàn bảo là khó tìm với dò hỏi rất lâu nhưng mình thấy có khó tìm lắm đâu vừa đến ngã tư tràng tiền hai bà trưng nó đã đập ngay vào mắt mình lần đầu tiên luôn rồi ý quán nằm trên tầng2 mình đặc biệt thích cách bài trí của quán từ lối lên tầng có chiếc xe đạp với mấy bao cát cầu thang có đèn treo lủng lẳng cho đến vào trong quán và cả ngoài lan can decor quán bằng gỗ bắt mắt đơn giản sắp xếp hợp lí không bị rối có ít cây xanh làm điểm nhấn và hài hòa trẻ trung mình thì thích ngồi trong nhà và chọn chỗ ngồi cạnh cửa sổ để ngắm phố phường rất thơ mộng mình nhớ có một dạo hay lên rồi bẵng đi một thời gian không lên rồi lại lên lại lúc đó đã mở thêm mấy cơ sở nữa nhân viên quán đã thay mới chứ dạo trước lúc còn chưa có cơ sở mới có mấy anh chị nhân viên người miền nam nói chuyện rất dễ thương hay cười với niềm nở chu đáo lắm giờ nhân viên mới toàn người bắc cảm thấy họ hay soi khách thái độ cũng không chan hòa bằng nhân viên cũ mình không thích cho lắm đến cofe house thường mình sẽ chỉ gọi đúng 2 món là trà đào cam sả và cafe sữa đá nếu các bạn đến cofe house các bác nên uống thử 2 món này vì theo mình thì nó cũng giống như đặc sản của cofe house vậy 3 giá thành cũng khá phổ biến như các quán khác giao động từ 30k đến 70k 80k gìđó và còn tùy thuộc vào size đồ uống', ' 1 tuần ghé quán mấy lần lận đó cơ sở 2 ni đẹp đẽ sáng sủa mát mẻ hơn nhiều nhìn là ưng cái bụng liền đồ ăn ngon mà lại rẻ lẩu xiên lạ lạ tokboki nướng phô mai ngon tuyệt đỉnh nhắc tới là lại thèm giá thì tầm 2030 thôi có lẩu thì cao hơn xíu mà giá rẻ mà đồ ăn nhiều lắm so vs cái giá như rứa ăn hoài k sợ hết tiền soda ổi thơm ngon nữa nèe       quán tỉ đông nên 1 là đi thiệt sớm 2 là 9h 9h30 đồ rồi vô cho ít người 3 đồ ăn làm nhanh kêu cái mô chừng 5p sau là có liền ăn đã thèm mà rẻ nữa ghé liền đi mấy chế ơi', 'shop của chị bé hàng xóm cute đầu tư tiền tỉ nên quành tráng lệ luôn chia làm 3 gian khác nhau   mặt tiền nên chỗ để xe còn hạn chế với chờ hơi lâu nha hôm bữa đi gọi mango smothie với matcha jely ice blended  ko biết cái smothie như nào nữa mà nghe con bạn nói cũng oke có điều nhìn cái ly mộc mạc ds còn ly matcha decor bắt mắt kinh nhìn là thấy thu hút rồi béo thơm mùi matcha thạch dai dai tổng thiệt hại tầm 50k hợp lý luôn', 'sandwich ở đây nóng giòn và ngon cực kỳ 1 phần ăn no cành hông mà còn có cả khoai chiên kèm khoai chiên được ướp gia vị ngon và rất độc đáo ở pq mấy ngày mưa là thích ở đây thôi', 'mình thấy hot trên facebok nên ghé ăn thử thấy bình thường thôi không có gì đặc sắc mà giá lại thấy hơi đắt so với chất lượng cá hồi ăn thấy okay nhất thui còn sushi cơm không được chất lượng lắm mì udon hay ramen nước dùng vị cũng khá đậm đà mà ăn hơi ngấy bánh xèo thấy ăn bị bột không hợp khẩu vị với mình lắm mình nghĩ chỉ nên ghé thử một lần cho biết thôi', 'đồ ăn nhìn ít mà ăn lại no quá trời        tb là 80k suất canh ăn nhạt k có vị gì nv hơi hời hợt quán ám mùi', 'không gian tuy hẹp nhưng khá là thoáng mát thích hợp cho tất cả mọi lứa tuổi tại đây ta có thể thoải mái lựa chọn cho mình những món ăn vặt cùng với các loại thức uống tùy thích   bên cạnh đó còn có thể tham gia các trò chơi giải trí thật đáng yêu cùng với bạn bè nhân viên vui vẻ phục vụ tận tình ngay cả anh giữ xe cũng thật thân thiện', 'đường đi vô xa dã man với tới chỗ ngồi thì nóng nực bẵt đầu gọi món thì mẹ ơi mình xài voucher nên k biết tại vậy hay s mà thái độ phục vụ kì qá kiu màk thèm quay lại luôn tới lúc quay lại thì trả lời cho có kiu nón ra thì lâu dã man rợ tuy nhiên ăn cũng đc mình kiu thêm sữa chua mít thì ngon nước có sấu dầm đs hà nội lạ miệg tại trog nam k có mà giá thì bình thườg so w mặt bằng chung nói chug ngoại trừ nhân viên kì cục ra thì qán cũg đc nên coi lại thái độ fục vụ thì chắc qán ok hơn nhiều', 'hôm qua mình mới ăn ở đây xong mình có một nhận xét như thế này về bài trí khá mát mắt phong cách trẻ trung nhưng ghế ngồi thì ko được thoải mái cho lắm vì phần lưng tựa của ghế thấp ai mà mỏi lưng muốn dựa thì ko có chỗ mà dựa đâu về đồ ăn tạm ổn về đồ uống pha chế chán lắm về giá cả hơi đắt mình có 3 người mà ăn có 2 đĩa cuốn 1 nồi lẩu nhỏ 3 cốc sinh tố hết gần 1tr tóm lại ko thích lắm bạn nào muốn thử thì nhớ là gọi từ từ rút kinh nghiệm từ mình gọi đồ ăn là mấy đĩa cuốn sau đó mình bảo từ từ rồi gọi tiếp thì nv ở đây nói là chị phải gọi lẩu luôn để chúng em còn chuẩn bị do vậy đến khi ăn cuốn xong thấy no no thì chỉ muốn đổi sang mỗi người tô bún nữa thôi nhưng ko được đổi nữa vậy nên ăn lẩu tiếp thì nó ăn ko hết mà lại còn bị lãng phí', 'uống th từ khi quán mới khai trương chắc cũng dc 23 năm gì rồi uống trà sữa ở đây là không muốn vào quán khác uống luôn giá có nhỉnh hơn thị trường nhưng tiền nào của đó thôi trà sữa lúa mạch với trà xanh táo là 2 món khoái nhất í mà giờ nge đồn hết lúa mạch rồi huhu không gian decor đẹp có từng khu vực riêng như bệt ghế ngồi khu học bài thích hợp mọi thể loại lun'), tensor([1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])]\n","1\n","[('1 nhà hàng nướng lẩu quen của t hot n tasty              t hay có thói quen đặt bàn trc ở đây đến nhân viên sẽ dẫn đến bàn và chỉ việc gọi đồ ăn thui thực sự chết mê chết mệt các loại thịt ở đây đa dạng và phong phú lắm từ thịt bò thịt heo thịt gà các loại hải sản bạch tuột cá ngừ ngao hàu rồi các loại thịt như cá sấu nữa nói chung là nhiều và ngon lắm thịt tẩm ướp đậm đà các món ăn sẵn cũng đa dạng salat kimbap hầu như cái nào cũng ngon lúc ăn xong thì có cả 1xe tráng miệng đẩy đến cho mình thoải mái lựa chọn khoảng 30k suất bufe nướng lẩu gọi thêm đồ uống hoặc suất hơn 30k có bao gồm đồ uống luôn phục vụ cũng nhanh nhẹn và cẩn thận lắm t hay đi ăn thứ 4 vì có chương trình giảm giá 50 cho suất bufe thứ 2 đó', '      món lạ nhiều hương vị vị ok nhân viên vui vẻ kem cuộn chưa khéo lắm quán nhỏ một bài chổ ngồi gần thùng rác hơi mất vệ sinh tip 20k ph', 'kem ở baskin robins rất ngon hay có ctrình khuyến mãi nữa đang có ctrình mua 1 tặng 1 đó mình được chị quản lý dễ thương giới thiệu mua kem lắc tặng 1 phần kem lắc kem hơi mắc nhưng br hay có nhiều ctrình khuyến mãi lắm nhất là mua 1 tặng 1 đó tính ra là quá rẻ cho 1 viên kem mỹ hiện đang có ctrình 25 k cho hsv nữa máy bạn tranh thủ đi ăn nha cử a hà ng sạch sẽ nv dễ thương mình sẽ tới ủng hộ hoài', 'tào phớ dâu tằm cái tên nghe hót nhất quán mà vào chửng mấy ai gọi may ra có mấy người thử lần đầu như mình cái nước dâu tằm ăn thật dị khi ăn vs phớ ko muốn ăn lại lần 2 mấy món ăn chính thì tạm gọi là ăn cho có chẳng ngon cũng chẳng ko ngon dưa su hào và kim chi ăn thêm thật thảm họa  ăn chua kiểu bị ỏng hay gọi là khú gê cổ', 'hễ đến đà lạt thì nhà thờ domaine thường được ghé tới à đến đây ko cần mua vé vào cổng mà khung cảnh cũng đẹp nữa nhà thờ cổ được chăm sóc kĩ nên vẫn còn mới và tươi sáng có nhiều góc chụp đẹp nữa', 'quán nhỏ đẹp trang trí mình rất thích giá cả phải chăng mà đồ uống lại ngon nữa mấy anh chị nhân viên rất nhiệt tình và dễ thương trà đào của quán rất ngon mấy món bánh lâu lâu lại thay đổi mình rất thích bán crepe xoài nhà quán ơi có view đẹp rãnh rỗi có thể đọc truyện nữa bla bla chỗ gữi xe fre nhen mấy bạn gữi bên nhà hàng 241 đối diện rồi qua quán đóng con dấu là xong', 'ưu nhân viên biết nở nụ cười có hàng dây leo xanh mát khuyết     quán quá tối cho dù là đang 10g sáng và đã bật đèn chè thập cẩm đúng thập cẩm thạch hạt lựu vàng đỏ từ trà sữa quả chery đỏ chóe từ kem vụn bánh quế giòn đậu xanh đánh không có hương vị bắc mà cũng không mang vị chè việt nam bãi giữ xe để lộn xộn và không có người dắt xe cho khách hàng dây leo xanh còn dính rác', 'ly nhỏ hơn nhưng vẫn ngon như thường            ', 'chủ quán rất tuyệt không gian mê ly ngồi tán dóc còn ngắm hồ nữa nhé he đồ ăn ko thể nào chê được đâu tóm lại rất tuyệt vời ya mình kết nhất món cánh gà nướng vị ngon thịt mềm ôi nói đến mà muốn ăn liền', 'bị ghiền trà sữa thái và bánh tráng cuộn ở đây', 'nước súp sánh sợi mì dai thịt chashu vừa ăn nếu đánh giá theo người việt mình là hơi béo nhưng đây là quán nhật mình ăn theo hương vị người nhật thì những món hôm nay mình ăn đạt chuẩn thực sự rất ngon sau khi ăn súp xong vị ngọt vẫn còn đọng lại nơi cuống họng cảm ơn bạn đầu bếp đã làm cho mình món ngon này cảm ơn các bạn phục vụ dễ thương lại chu đáo hẹn sớm gặp lại quán này gần nhất 3', 'nằm trên đường phan châu trinh quán có không gian nhỏ nhưng sạch sẽ với phông màu bắt mắt menu đa dạng tào phớ ngon miệng lại còn rất đẹp mắt nữa giá cả thì không quá cao tofu hơn cả tào phớ ', 'đợt tháng 10 thấy quán này đăng tin chuyển nhượng chẳng biết đã đổi chủ hay chưa mà nhìn khu bình luận thấy bao nhiêu người make color lộ liễu quá chiều hôm nọ đưa cháu đi học ở trường herman gmeiner gần đó tiện rẽ vào thử xem ngoài cửa treo biển tuyển nhân viên ban đầu mình tưởng tuyển nhân viên order nhưng nếm patbingsu rồi mới ngờ ngợ có khi là tuyển nhân viên pha chế làm đồ vì 3 món mình gọi khá tệ bạn nam công nhận nhanh nhẹn cơ mà nói nhanh khó nghe rõ với lại làm gì có tư vấn chọn đồ nhiệt tình như các bạn trước phản hồi đâu tầng 1 cứ tôi tối   tầng2 thì ám mùi mốc giá không rẻ khi so với chất lượng dưới trung bình thế này đại khái là tổng chào tạm biệt quán', 'khá ngon và hấp dẫn do quán đã có lâu đời nên cũg có thương hiệu phục vụ tốt sức chứa lớn', 'quán rất đông khách dù không phải là ngày cuối tuần giá cả phải chăng khách hàng có thể tự lựa chọn món ăn có nhân viên nướng tại bàn nhân viên giữ xe lịch sự phục vụ cũng ok nói chung là sẽ ghé đây thường xuyên vì chất lượng tốt và gần nhà', 'quán ở ngõ 47 đường nghĩa tân nên tìm hơi khó cứ đi loanh quanh là tìm thấy quán quán ở đây có món cơm trộn bò gà lợn của hàn quốc mua đông mà ra đây ăn thì cực ngon vừa nóng vừa cay cơm trộn chỉ có 35k thui à nếu muốn ăn rẻ hơn thì ăn loại thịt lợn thì có 30k'), tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1])]\n","2\n","[('mình biết nhà sách này lâu rồi hôm nay mới có dịp ghé vô mua đồ mình tính đi coi thôi nhưng rốt cuộc cũng mua được vài món hehe ấn tượng của nhà sách là trang trí rất đẹp mỗi tầng bán mỗi loại khác nhau   tầng trên cùng có cả quán cafe mình thích view của quán này chụp hình checkin đẹp lắm giá bán cũng tùy loại có loại giá cao có loại giá cũng bằng các nhà sách khác các bạn nhân viên được cái dễ chịu mình hỏi thông tin về cái đèn bàn học prism hàn quốc cho cháu vì thấy cái đèn này rất đẹp so với các loại khác thế là bạn nhân viên ở đó tư vấn rất nhiệt tình sách ở đây có nhiều cái mình không thấy bán ở siêu thị khác có chỗ ngồi đọc sách miễn phí cũng hay lắm các bạn ghé thử xem', 'quán đẹp view cũng đẹp nhân viên nhiệt tình nhưng đồ uống thì không ngon chút nào đã vậy giá còn không hợp lí', 'biết bobapop cũng đã lâu nay gần nhà có chi nhánh nên cũng thấy thích đến lần đầu và chắc chắn k quay lại nữa   chất lượng nước không ổn lắm mình gọi trà sữa mức đường và đá ít nhưng nước lúc bưng ra khá lỏng lẻo giống kiểu pha thêm nước lạnh cho đầy ly bánh boston phải gọi là k có gì ấn tượng y chang một cái bánh bông lan bình thường nhân viên phải gọi là cực kỳ ồn ào nhạc mở đã to mà tiếng nhân viên còn to gấp mấy lần nhạc nói chuyện chưa đủ phải la phải hét lên làm mình thấy rất khó chịu muỗng nhựa ở quán khách xài xong mấy bạn rửa xài lại mình biết là để tiết kiệm chi phí và muỗng nhựa k thân thiện với môi trường nên các bạn làm vậy nhưng các bạn có thể chuyển qua xài muỗng inox hay gìđó hay hơn mà nếu các bạn xài muỗng nhựa lại thì rửa lau chùi gìđó thì nên sạch sẽ và kín đáo tí đằng này lau xong tay các bạn lại bốc vào muỗng thì cũng như không ly đựng còn đóng bợn nữa', 'tịêm bánh mì này là ở cẩm lệ mình ghìên nhất lun bánh mì giòn nóng nhân ở trong cũng ngon nữa nhân viên toàn mấy chị nhịêt tình với dễ thương tịêm còn bán thêm bánh ngọt để phục vụ cho sinh nhật nữa trang trí rất đẹp bánh ngọt vừa phải giá cả phải chăng nữa sinh nhật nào hầu hết mình đều mua ở đây còn sáng nào đi học trễ thì tạt vào đây mua mấy chị làm nhanh lắm nên cũng không sợ trễ', 'waterland suối thạch lâm   mery christmas   hapy new year kính gửi quý khách hàng một mùa giáng sinh an lành   đón chào năm mới 2014 lại về hứa hẹn những điều tốt đẹp sẽ đến thay mặt bgđ khu du lịch waterland suối thạch lâm chúng tôi xin trân trọng gởi đến quý khách hàng lời chúc sức khỏe   thành công và thịnh vượng cùng chương trình đặc biệt thời gian từ 21 12 2013 đến 01 01 2014 chính sách ưu đãi tặng miễn phí vé trượt nước cho tất cả khách hàng tham quan khu du lịch khách hàng mua vé rafting   tặng vé trượt cỏ   miễn phí chơi minigolf cho trẻ em tặng 01 ảnh tập thể cho đoàn từ 10 khách trở lên kdl waterland suối thạch lâm là điểm tham quan dã ngoại lý tưởng với cảnh quan thiên nhiên đẹp mắt nhiều trò chơi thể thao vui nhộn sảng khoái là địa điểm thích hợp cho các hoạt động teambuilding dã ngoại gala liên hoan hội nghị', 'quán này có hai lầu nhưng mà bữa mình đi ngồi ở lầu một nhân viên khá dễ thương tư vấn nhiệt tình món khai vị là súp và bánh mì bơ tỏi súp thì mình ăn không quen nên thấy nhạt không có mùi vị gì đặc biệt bánh mì được cái thơm chứ cũng bình thường mình gọi 1 phần combo và 1 mì ý mì ý khá nhiều sốt kem ngon ăn rất vừa ý còn combo thì thịt bò làm mềm thịt ngọt mình thích khoai tây nghiền ở đây chưa phải là mịn lắm nhưng cũng tạm chấp nhận được ăn béo và rất thơm nước sốt bq thì tuỳ người ăn riêng mình thấy không ngon tráng miệng là bánh flan có điều quên chụp ăn ngon bánh làm mịn mà bữa mình ăn hình như là bánh đã được khè lửa trước rồi bỏ tủ lạnh chứ không phải mới làm ăn cái biết liền ak hơi ngán tí giá cả phù hơp so với nhà hàng', 'chiều hôm qua tới quán thấy lô bên ni đóng cửa tưởng quán hôm nay nghĩ bán té ra lô bên cạnh mở cửa tại quán rộng quá mà 3 lô đất gộp lại luôn đó quán rất sạch sẽ nhân viên thân thiện chú chủ quán mà giống như nv ấy hết chạy đi mua bia rồi chạy đi mua bún mình lười nướng nên nhờ quán nướng giúp đồ ăn tươi ngon và nướng rất vừa ăn nữa đặc biệt nước chấm muối ớt xanh quán làm rất ngon chứ ko pải dùng chai mua sẵn như nhóp nhép   chai mua sẵn người ta làm quá ngọt làm cho đồ nướng mất ngon mấy phần mình chỉ mong quán làm tàu hủ đa dạng thêm tý nữa vì mình rất thích món này', 'mình vào quán uống mấy lần rồi thật là thanh hoá không có nhiều quán để mình đánh giá ngon được nhưng thật là gatino đồ uống ngon thật đấy hôm nay mình uống caramel jely đá xay và nước chanh dây caramel mình uống thì tuyệt vời nước chanh dây hơi chua tí thôi hồi trước từng thử kem ở đây rồi cũng ngon lắm về vấn đề đồ ăn đồ uống ở đây thì mình k chê chỗ nào được không gian rộng rãi thoải mái bố cục khá có phong cách chưa được thử cái vụ nhạc sống ở quán có chỗ để xe rộng rãi nhân viên thân thiện nhưng có điểm trừ như sau nhiều món không có trong menu mình mấy lần hỏi mấy món bàn bên gọi thì họ bảo do khách thích thì gọi mình thấy vô lý quá mà mấy món được gọi đấy thì giá cũng ko ai biết luôn tại mình thấy có 1 bạn gọi một món gì mới mới tên kêu lắm ra tính tiền mới ớ nó những này tiền cơ ah đóng góp ý kiến một chút xíu là nên bổ sung tất cả vào menu ạ chứ không khách hoang mang lắm hết', 'tự nhiên thèm ốc nên mình rủ bạn đi ăn nghe mọi người khen quán này quá trời nên mình cũng đi thử cho biết không gian quán nằm trong hẻm nhưng là hẻm lớn rất dễ kiếm quán hơi nhỏ nhưng sạch sẽ lắm món ăn mình gọi ốc cà na rang muối ớt ốc tỏi xào bơ cơm chiên muối ớt hàu nướng phomai ốc cà na rang muối ớt ngon bá cháy luôn nhé ăn xong 1 dĩa lại muốn kêu thêm nhưng cay quá ko ăn nổi nữa ốc tỏi xào bơ bơ thơm lắm luôn ăn kèm với bánh mì điểm trừ là bánh mình dở quá nguội ngắc à cơm chiên muối ớt mình thấy món như tên gọi chỉ có cơm muối ớt hơi thất vọng 1 tí nhưng đc cái mùi vị cũng được hàu nướng phomai con hàu hơi nhỏ nhưng ngon giá cả chấp nhận được mình gọi mấy món trên và 2 chai coca hết 150k phục vụ tốt', 'quán nằm gần trung tâm nhìn ra bờ kè rất dễ thương nhiều lọai nước uống ngon với giá rẻ hôm tết đến uống nước còn được tặng cuốn sách an lạc từng bước chân của thiền sư thích nhất hạnh         điểm dừng chân lý tưởng để thư giãn uống trà đọc sách của mình nghe nói quán dùng tòan bộ lợi nhuận cho việc học tập và từ thiện nên mình cũng muốn đóng góp chút ít thay vì đi những quán nước khác', '  mình ko ăn ở chỗ này vì bạn gái mình học bên q7 nên hay ghé bên khu him lam ăn hơn nói chung là rất ngon cá thu thì hết sảy    nc chấm cá ngon lắm luôn ăn hoài mà vẫn ghiền hoài sushi cá trích ép trứng cũng ngon tuyệt túm lại là tuôi thấy đã lắm đó đồng bào', 'vừa ăn xong bánh mỗi người chỉ 1 cái là ngán bông lan chưa được xốp mềm phomai nướng khô cứng ko còn vị béo', 'không gian đẹp có nhiều loại bánh món patbingsu trái cây cũng bình thường xoài hơi chua quá', 'tớ biết quán này rồi vào đây ăn thịt chuột thì ngon tuyệt vì chuột cống ở đây chắc quán nuôi nó chạy lông ngông dưới chân ấy con nào cũng to khỏe cả mập lắm hú hồn', 'chè ở đây theo mình rất ngon độ ngọt vừa phải 1ly 8k mà đậy ụ đôi khi nghĩ là chỉ ăn1 ly thôi nhưng ngon quá nên quất luôn 2ly chị chủ thì vui vẻ dễ thương thân thiện quá chừng ngày nào mình cũng ghé ăn ngày nào mưa không ghé được là thấy thèm quá nhớ chị chủ dễ thương nữa tầm chiều là khách đông lắm phục vụ không kịp luôn mấy bạn thèm chè thì nhớ đến ăn thử nha d', 'đồ ăn ngon giá cả hợp lý đúng chất đồ ăn vặt mình ghé lần thứ 3 ngồi phía nhìn ra cửa sổ tối rewiew đẹp nhân viện tận tình chu đáo đồ ăn đa phần ngon nc chấm đa dạng đồ uống riêng chỉ có dừa tắc hơi ngọt mình uống ko thấy hợp'), tensor([1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1])]\n","3\n","[('lần đầu bước vào quán cảm thấy như đang đi biển vậy mình gọi ly cean mermaid ngon lắm hình như 27k còn bạn mình thì gọi lu lemon try cũng 27k mà ko đc ngon cho lắm nói chung là cũng đc nhân viên thân thiện dễ thương lắm sẽ ghé lại quán hihi', '  khách sạn đẹp bày trí sang trọng tiện nghi phục vụ dễ thương bãi biển sạch đẹp thức ăn tuyệt vời từ set menu đến bufet đều tuyệt vời các loại bánh ngọt ít đúng vị không ngán', 'mình và mấy người bạn thèm món nướng chạy tìm quán nướng ngói nào đó ăn thấy quán này nên tấp vô ăn luôn giá cả quá rẻ luôn mà đồ ăn ngon và chất lượng lắm mình thích nhất là món bò cuộn nấm ở đây hải sản tươi rẻ nêm nếm vừa ăn nướng than tại bàn ăn thơm nức luôn nhân viên hiền lành dễ thương quá trời luôn àh chắc chắn mình sẽ ghé ăn nữa', 'gia sư dạy kèm tphcm chất lượng đảm bảo   gia sư việt mỹ website htp w giasuvietmy com hotline 0909 7979 26 0967 797927 trung tâm gia sư việt mỹ là 1 trong những trung tâm gia sư uy tín và lớn mạnh ở tp hcm   với đội ngũ giáo viên và sinh viên chuyên dạy kèm tại nhà gia sư tại nhà tphcm nhiều năm kinh nghiệm khắp trong thành phố nhận dạy tại trung tâm và dạy kèm gia sư tại nhà các môn toán lý hóa   tiếng anh   sinh văn sử địa các lớp 123 45 67 89 10 12 luyện thi đại học   dạy kèm ngoại ngữ tiếng anh   tiếng nhật   tiếng trung   tiếng hàn   tiếng pháp và tin học cho các học viên ở mọi lứa tuổi ngoài ra chúng tôi còn dạy các môn năng khiếu như cờ vua   cờ tướng guitar organ   piano dạy kèm tại nhà tất cả các quận ở', 'mình có vô ăn1 lần lúc mới mở không biết tại xui hay sao chứ bữa đó kêu set nướng thập cẩm đồ ăn ít thịt dai không nghĩ là sẽ quay lại nhưng được cái không gian cũng tạm ổn', 'đã từng đi ăn ở điện biên phủ tiếc là không gian hơi hẹp nên mình thử ăn ở phan văn trị vì nghe nói không gian thoải mái hơn chất lượng thức ăn tạm ổn lẩu miso hơi mặn mực trong lẩu dai vú heo thái dày xà lách số 6 không có vị gì luôn bàn ghế thì thua xa bên đbp  vì bàn cao quá ngồi không thoải mái cái bạn lại to hơn bình thường nữa 2 người mà ngồi đối diện nhau thì tưởng chừng cách xa vạn dặm cái tệ nhất chính là thái độ của nhân viên phục vụ ở đâu ra mà nhân viên kêu ăn gì thì nói để đem một lần luôn phục vụ không nở được một nụ cười mình bỏ tiền ra ăn chứ đâu phải ăn miễn phí đâu mà coi khách hàng không ra gì   mình quyết định không tip vì thái độ phục vụ quá tệ hóa đơn là 51 10vnd   mình kẹp vào 51 50vnd  và ra chỗ thanh toán thì nhân viên kêu mình lại nói chị khỏi đưa 50vnd cũng được chắc bức xúc vì mình không đưa tip mình không phải dạng không chịu chi típ nhưng tip đúng người đúng chỗ chứ nhân viên coi thường khách hàng như vậy mà đòi típ thì hơi quá đáng chắc chắn mình sẽ không ghé đây nữa', 'đọc nhiều coment khen và công ty ở gần nên cùng mọi người ra ăn cũng biết đến quán từ lâu vì quán cực kì mạnh tay chi tiền cho digital marketing ăn xong hơi bị thất vọng với giá tiền này thì ko nên hi vọng gì cả thích hợp cho học sinh sinh viên để ăn cho vui hơn là để thưởng thức đồ ăn ở đây bình thường mì và cơm trà xanh là điểm nhấn ăn cơm thì mùi trà rõ hơn ăn mì nước của mì kim chi nhạt nhẽo ko rõ mùi mì trà xanh cá ngừ thì là loại cá ngừ hộp ko có gì đặc biệt rau cải non có lẽ là điểm nhấn tốt hơn mì xúc xích bình thường ăn như loại mua ở siêu thị kim chi cũng quá thường nama chocolate khá tệ vị dâu và trà xanh có mùi hóa học và vị đường quá nặng mùi chocolate và vani thì ngọt lừ đây ko phải là chocolate tươi ngon nên ai đã từng ăn ở chỗ khác thì đừng hi vọng gì mof ăn tốt hơn bù lại có lẽ là giá cả rẻ bèo 40k hộp 16 viên nhưng mình thà bỏ nhiều tiên hơn ăn hộp 12 viên đúng nghĩa sô côla tươi hơn là ăn như thế này ăn về sợ vị ngọt sắt của nó luôn pana cota ăn tạm được mùi trà xanh hơi bị quá nồng và hơi ngọt quá nói chung món này là khá nhất trong tất cả các món mình đã thử hôm nay', 'phục vụ chậm chạp đồ ăn thì order 1 tiếng sau mới có order lẩu nấm thì bảo 1h nữa mới có lẩu cháo hào cũng 1h sau order món miến thì nói ko có chỉ có mì làm nhanh 20 sau mới có mì order món nướng từ khi vào đến 1h rưỡi sau mới có order thêm món hến bánh đa thì mãi ko thấy ra nhưng khi tính tiền thì tiến cả món chưa mang ra ko thể ghé lần 2 đc nữa đợi món còn hơn đợi người yêu vậy', 'cứ nghĩ ít nên gọi 3 món ai ngờ nó nhiều kinh khủng xôi dẻo thơm thịt gà ăn cùng vs xôi khá hợp định gọi xôi thập cảm nhưng thôi chắc phải để lần sau tào phớ ở cơ sở này đỡ chua hơn vị chua dịu khá hợp với mình nói chung hôm nay khá ưng với mức giá 10k cho bữa này', 'mình ăn từ khi quán bán online đến giờ sushi ngon đa dạng chủ quán nhiệt tình ship gò vấp rẻ lắm 5k hoặc freship luôn ủng hộ dài dài', 'mình ko biết chất lượng khi gọi món như thế nào nhưng khi mình mua voucher để dùng thì thật sự rất rất tệ cua lạt nhách tôm có mùi hôi ốc ăn tạm tạm ếch và gà nướng ko chín hàu thì thôi rồi mình phun ra luôn đồ ăn lạnh ngắt dù mình sử dụng deal thì cũng nên tôn trọng khách hàng chút chứ hèn gì dù deal rẻ mà xung quanh rất ít khách ngày thường mình tới còn ko có khách mình ăn chút xíu đứng dậy về vì sợ bệnh', 'lâu rồi mới quay lại quán quán vẫn dễ thương như ngày nào trà sữa vẫn ngon đặc biệt là các loại thạch trái cây nhai sựt sựt dai dai chua chua ngọt ngọt ngon miễn bàn luôn còn trân châu thì chưa được dai mà mềm mềm nhìn chung 1ly trà sữa trân châu thạch trái cây 2k như vậy khá là hài lòng không gian dễ thương nhạc hay nhân viên nhiệt tình', '1 quán đồ ăn vặt rất hay ho mà lại nằm ngay trên trục đường trong khu phố cổ gần bờ hồ đồ ăn ở đây mình coi như mỗi món là 1 món quà vậy toàn những thứ ngày xưa thuở bé hay được mẹ mua cho từ mấy cô hàng rong í nhưng giờ thì không còn đâu ạ chỉ có lưa thưa 1 vài thứ còn được bán rong thôi còn đâu muốn ăn kiếm là mỏi mắt mỗi món lại rất chi là rẻ nữa với khách nước ngoài hay không biết cứ mua mỗi thứ 1 ít ăn lúc buồn mồm là tuyệt vời ạ', 'quán dễ thương bánh ngon mình đi buổi trưa nên vắng khách khá yên tỉnh', '    vị trí không gian nhà hàng thuộc seahorse resort nên nhìn cũng khá đông vui nhộn nhịp buổi tối mình đến ăn phải bok bàn trước chứ đến là không còn chỗ nhà hàng có không gian rộng và rất thoáng đãng quầy hải sản được đặt ngay trước cổng ra vào và được decor dưới dạng chiếc thuyền ngập tràn hải sản nhìn rất hấp dẫn khách sẽ order hải sản ở quầy luôn đầu bếp sẽ chế biến và mang vào cho mình sau chất lượng nghe nói lẩu thả là đặc sản của phan thiết và nhà hàng chế biến món này khá ngon nên order luôn và quả thật ko làm mình thất vọng món lẩu khá đặc biệt với các thành phần lạ so với món lẩu thông thường như xoài trứng chiên thái sợi cá đục tái chanh gừng bánh đa sau khi trộn bún vào thì có 2 cách ăn là khô và nước mình thấy ăn kiểu nào cũng ngon hết nếu chưa biết cách ăn sẽ có nv chỉ mình luôn cơ mà hơi tiếc 1 chút là món ăn ko được trình bày lên cánh sen đẹp như mình thấy trên web hào nướng phô mai hào con to và tươi lắm phô mai ngậy và thơm lừng rất ngon sò điệp con to thịt dai dai ăn ok lắm giá cả tụi mình gọi lẩu thả nhỏ dành cho 2 người giá 350k mà ăn được 4 đứa lận mỗi tên đc 1 tô bự nhé hào 29k con sò điệp 43k đĩa 6 con tôm hùm mình ko ăn nhưng thấy giá khá mềm nhà hàng mà bán 1tr kg thôi dịch vụ siêu siêu dễ thương mình mới than nóng nóng là có bé nv chạy vô bê cái quạt máy ra liền luôn nói chuyện nhẹ nhàng nhưng cũng rất niềm nở khiến mình thấy cực kỳ thoải mái và hài lòng', 'tiệm bánh mình nghe nói mọi người nói ăn rất ngon nên đã đi đến chỗ mua luôn thấy bánh cũng ngon giá rất rẻ so với mọi nơi nhưng khi đến mình hỏi lại thì giá cao gấp 4 lần sao vs giá niêm yết'), tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0])]\n","4\n","[('quán này gần nhà bữa đi ngang thấy nên ghé ủng hộ thức uống bày trí bắt mắt ngon và giá cả rất ok kết nhất chủ quán dễ thương vô cùng', 'quán này được đó chứ nhậu ở đây mấy lần thấy mặt bằng thoáng mát rộng rãi đồ ăn cũng ngon hợp vệ sinh', 'gần lễ rồi được nghỉ sớm nên lon ton chạy vào đây ăn gấp được bạn giới thiệu nói chỗ này bán rẻ khá nhiều vs chất lượng hơn so với mấy quán khác mình vào gọi bò né với người yêu mình thì mần thử món bò kho opla rất vừa ý một phần 25k gồm thịt bò pate trứng bên cạnh đó 15k cho phần bò kho cảm thấy khá hợp lý fre salad bánh mì và trà đá mình có gọi thêm sữa đậu xanh khá thơm và béo khá là thích lúc mình ăn là tầm hơn 7h30 sáng khách cũng khá đông phần lớn học sinh và gia đình nhưng lên món rất rất rất nhanh luôn í thích lắm mình nghĩ với 25k thì như vậy là quá ổn nhất định còn ghé lại nếu thòm thèm', 'mình với con bạn ăn quá trời luôn 1 phần tầm 25k 35k 3 viên thì phải món này ăn vặt mà 2 con ăn no nên hao quá hao mỗi đứa 150k mới no nhan viên lẫn chủ siêu dễ thương không gian quán nhỏ coa nhiều đồ chơi nhật trong lúc chờ bánh ra thì ngồi chơi cũng vui lắm', 'quán rất rộng mùa hè có quạt phun sương trên đầu là cây rủ xuống khá mát thức uống thì rẻ ăn bình thường nhân viên cũng không nhiệt tình', 'quán vừa nhỏ tý lại còn vừa đắt nhân viên thái độ lồi lõm thôi rồi đúng là mấy em trẻ trâu lần đầu tiên được va chạm đi làm nên vùng vằng mặt mũi sưng sỉa lên nhìn là đã không muốn ăn tự nhiên đồ đang ngon lại thành chán rồi ý giá trung bình toàn từ 50k trở lên   suất cơm hoặc miến trộn uh thì công nhận gia vị nêm nếm khá vừa miệng cũng ổn cơ mà mỗi một suất được có 1 tý tẹo ăn chả bõ ăn tối kiểu này thì ăn xong vẫn còn đói meo ý ôi nước hoa quả đây như kiểu siro hóa học pha chế vào ý vị nước cam uống ngọt lợ khé cổ kinh không tả nổi còn kiểu có ga nên uống kinh khủng lắm quán chật chội thật khổ tâm cho những ai thân hình quá khổ mà chui được vào đây ngồi ăn', 'đây là lần đầu mình đến đen đá cảm thấy khá là thích quán có hương thơm nhè nhẹ không gian nhìn chất lắm giá rất ổn so với mặt bằng chung ở q1 và q3 trung bình khoảng 35 đến 40k khá là ưng gu nhạc rất tốt', 'nằm ngay gần góc mạc đỉnh chi và nguyễn đình chiểu   nhà hàng mama với màu xanh bắt mắt như là 1 lâu đài được trang trí hiện đại tối thư 7 đi nhà hàng tầm 8h là thấy rất đông nhân viên chào thân thiện với khách hàng lắm luôn phục vụ rất chu đáo không gian bên trong thì rất lộng lẫy chia ra nhiều khu riêng tạo cảm giác thoải mái cho khách khu sân vườn thì rất lãng mạn sau này mình sẽ tổ chức tiệc ở đây được nhân viên giới thiệu cho các món của nhà hàng ăn rất đặc trưng như là trứng con rể với sốt me trứng được chiên ăn lạ và rất ngon trà sữa thái đỏ 5k rất ngon ngon nhất trong tất cả quán thái đã từng uống thơm béo k ngọt ngắt bánh táo tráng miệng 70k ăn rất ngon sẽ quay lại thường xuyên vì rất thích nhà hàng này', '2k đc 2 miếng đào giòn to rẻ hơn những quán tôi từng uống', 'quán nhìn bên ngoài khá nhỏ làm mình tưởng tượng chỉ chứa nổi 1 bàn nhưng vào trong thì khá bất ngờ khi thiết kế rất đẹp và cũng to hơn mình tưởng nhân viên thân thiện menu đa dạng từ nước ép đến sinh tố sữa chua và salad không gian nhỏ mà biết cách bài trí nên nhìn rất hay có mấy hình vẽ trên tường sáng tạo lắm bưng nước ra hồi có bạn phục vụ hỏi mình có vừa miệng không thấy thích thích so với mặt bằng ngay trung tâm thì giá không quá cao nhưng so với túi tiền sinh viên nghèo thì không hề rẻ tí nào', 'quán nhỏ xinh nhân viên đc lúc đầu nếm kem chưa kĩ thấy vị kem giống loteria  mà trong khi đó kem loteria có 3k cây nhưng tiền nào của đó càng ăn thấy càng ngon và vị có sự khác biệt rõ kem tuơi béo vừa và ngọt vừa toping chất luợng dâu đà lạt đàng hoàng siro cũng dạng xịn ăn phần kem strawbery 60k ngon', 'sao mình xem trong thông tin fody lại thiếu mất số dt nhỉ đang đói bụng mà ức chế', 'bánh ở đây ăn không ngon giá cả thì cũng vừa phải mình ăn ở đây một lần bị bánh dùng bột cũ hay sao đó làm cho vị bánh chua khó ăn lắm nên mình quyết định không ăn ở đây nữa tối tối ở đây có bán ốc có vài món ốc như luộc hay xào me ốc ăn thì được chứ đừng ăn bánh cuốn nếu may không gặp bột cũ như mình thì cũng chẳng ngon lành gì cả đâu', 'nhà hàng với phong cách sang trọng nhưng thức ăn từ dĩa nhựa hũ nhựa ly giấy không khác gì ở aeon mình order trà nóng miso sashimi cá hồi 2 phần sushi cá trích ép trứng 2 phần maki maki cua thì nhận được thanh cua tức là cá ướp hương cua đến nhà hàng nhật thì mình luôn order trà thì nhận đc trà túi lọc vn mà hoàn toàn không hề thơm màu vàng nhạt tệ hơn loại trà fre ở ngoài quán cà phê 10k ly súp miso hình như pha từ bột hoàn toàn không có vị thanh từ rong biển mà là chua chua maki làm không đúng cách lúc mình ăn thì 1 gia đình khác vào ồn không tả được với chất lượng như vậy thì mình nghĩ qua aeon sẽ tiết kiệm đc khá tiền', 'bình luận 1 tí lúc trưa này mình vào aeon mal đi mua sushi mà lại hết nước tương chỉ có mỗi mù tạc ko định kiếm chỗ nào vặt vặt mua thêm để xin luôn nước tương ăn sushi lên lầu 2 thì thấy quầy hotbox định chọn mấy cây cá viên nhưng nhân viên ko thấy nhìn kĩ lại thấy nằm ngủ trong kia cái đi qua quầy kế bên là hongkong deli mình chỉ mua 2 chén chè khúc bạch 15kchén     thấy chỉ có mỗi loại vị khúc bạch vải hỏi thêm còn vị nào ko thì nviên à ko phải nviên nữa thấy cũng hơi xồn xồn giống như quầy tự chủ trả lời giọng thấy ghét quá trời   nói là chỉ có mỗi loại vải này thôi chứ có loại nào khác nữa đâu hức hức giờ review chè nè e hèm ko biết có ai đã từng ăn ở hkdeli chưa mình là mình chưa ăn rồi đó chỉ ăn có mỗi chè khúc bạch thôi chè thì bị nát giống như tàu hủ à ko nát quá vậy chỉ là nó sứt sứt mẻ mẻ cầm muỗng lấy ăn1 hồi là bảo đảm cái chén toàn xác chè nhỏ nhỏ rớt xuống mình nói thiệt á tuy nhiên cũng ko thể so sánh chè ở đây với mấy quán chè khác đc nhưng bù lại lầu 2 rộng mênh mông kiếm chỗ ngồi cũng tiện nữa lúc ăn xong cầm khay bưng lại chỗ thùng đựng rác thì đc chị nviên mặc đồng phục nói cơn rất lịch sự', 'mình cảm thấy đồ ăn quán này làm rất vừa miệng nhưng phục vụ còn hơi chậm quán rộng rãi và thoải mãi'), tensor([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1])]\n","5\n","[('mình mới tổ chức sinh nhật ở đây thấy thức ăn và chất lượng rất ok đặt biệt là bàn mình được giảm 30 thức uống sinh nhật mình mọi người uống tẹt ga và quẩy hết mình mình ko ngờ ở gò vấp có một nơi tuyệt vời như vậy', 'nghe khen cũng đi thử cho biết ăn xong phải nói là thất vọng nặng nề trước hết là đồ ăn dở đều tôm sú lớn hơn con tép chút nghêu thì vỏ to nhưng thịt như con hến hải sản ăn ko có cảm giác tươi gì cả xúc xích thì toàn bột cánh gà cajun mềm nhũn ko giòn vị cũng ko ngon nhạc thì giựt rầm rầm ko có khẩu vị ăn luôn phục vụ thì mặt ko thấy dc nụ cười làm như mình nợ tiền bạn ấy ko bằng khi vào quán thì chạy ra mở cửa nhưng khi bước ra thì mặt tất cả các bạn đều đơ như cây cơ nói chung là điểm 10 cho tệ nhất', 'quán có nhiều bánh lạ mùi vị rất ngon thích nhất là độ ngọt vừa quán trang trí đơn giản thôi phục vụ rất nhiệt tình à ngoài bánh còn nhiều món ngon nữa vị rất tây bạn mình đi du học về ăn befsteak và pasta khen ở đây nấu không việt hóa   rất giống đồ an bên mỹ', 'hồi tối được con bạn chở đi ăn hehe dù xa ơi là xa và đường xe đông khó chạy nhưng bù lại chất lượng thì điểm 10 luôn ăn tô lớn 50k còn tô nhỏ thì 40k đáng đồng tiền bát gạo lắm chứ không có cảm giác tiếc nuối gì luôn ghẹ tươi ngon ngọt lắm không hề tanh nữa bánh canh và nước súp khỏi chê luôn mà có cái miếng vàng vàng đó mình không biết gọi là gì hichic mà miếng đó ngon lắm á nước chấm đi kèm nhìn rất lạ cay xè luôn mình đoán hình như là muối chanh ớt thì phải 3 ăn rất hợp với ghẹ tô to oạch nhìn tưởng ngán lắm mà ai ngờ ngon quá xá ăn xong tô nhỏ mà nghĩ bụng phải chi kêu tô bự ăn cho phê hehe anh nhân viên lịch sự nữa có ra dẫn xe giúp tụi mình luôn kết quán này rồi đó 3', 'thức ăn ngon vừa miệng khá giống cách chế biến bên thái nhiều hơn các nơi khác nhân viên tận tình dễ thương     lẩu ngon giá khuyến mãi lại càng cực hợp lý luôn', 'mình đến lúc buổi trưa quán khá vắng nên ko bật máy lạnh hay sao   nóng kinh khủng về phần nước uống thì có vẻ không được cảm tình cho lắm ở đây pha hơi ngọt matcha không đúng vị soft cream thì đưa ra xiêu vẹo nhìn rất xấu ăn chỉ thấy béo chứ ko thấy mùi trà xanh đâu nói chung từ phục vụ đến thức uống đều thất vọng cả hi vọng quán cải thiện', 'trước giờ mình toàn ăn dốc nhà làng với phan đình phùng mà nghe chỗ này ngon tráng lết xác tới ăn cảm nhận là thà nhịn đói nếu như mí chỗ kia nghĩ bán vừa mắc vừa dở tệ', 'quán này không gian rất thoáng đãng quán này có 3 khu cho bạn lựa chọn ngoài sân khu này rất thoáng mát có hàng rào được lấp đèn rất đẹp bàn ghế là các loại bàn nhỏ từ gỗ rất là sáng và đẹp khu thứ hai là trong nhà tầng 1 trong này rất ấm cúng có vẽ tường chụp ảnh ở đây thì rất đẹp bàn ghế chủ yếu là nệm ngồi rất yêm khu này bày trí theo lối cổ điển nhìn rất là đẹp ngoài ra quầy pha chế đặt ở đây bạn mà ngồi ở khu này thì bạn sẽ ngữi thấy mùi cà phê rất nồng nàng riêng khu cuối cùng mình thích nhất là tầng2 ngồi rất thoáng có thể nhìn ra không gian bên ngoài từ trên cao ở đây khá lông gió ngồi mùa hè thì mát thôi rồi nước uống ở đây khá ngon mình đến đây thường chọn cà phê rang xay nó rất chi là thơm ngoài ra capuchino ở đây cũng rất tuyệt vời nhân viên của quán rất nhã nhăn năng động và rất biết chiều lòng khách giá cả ở đây cũng rất tốt', 'sáng mình và gia đình có ghé vào ăn kêu 4 tô mì quảng gà quán này nằm ngay đường nên rất dễ kiếm phục vụ nhiệt tình vui tính món ăn thì cũng bình thường k quá đắt 25k 1 tô đợi 5 phút là có rồi quán sạch sẽ rộng rãi nhưng không có bảo vệ trông xe vừa ăn vừa ngó xe nên mình không hài lòng lắm gà thì mềm nhưng nước hơi mặn ăn kèm với rau và bánh tráng thì đỡ hơn nếu thích có thể xin thêm nước mì tùy thích  ', 'ghé quán này rất nhiều lần đồ ăn cũng được tuy nhiên nên điều chỉnh giá cả cho hợp lý vd rau câu sương sa bằng ly trà đường nước uống đơn giản mà còn mắc hơn đồ ăn hôm bữa mới ghé lần nữa và chắc cũng là lần cuối gặp bạn nhân viên xà mâu bưng ly nước dĩa đồ ăn ra mà thảy xuống cái ạch kèm với thái độ rất là lịch sự còn nữa là quán làm đồ ăn rất lâu', '17k lạng bạch tuột bò lá lốp 12k phần chân gà nướng và các loại đồ nướng khác bạch tuột ở đây ăn rất ngon tươi và rất giòn khi ăn bạn nên ăn suất 3lạng nhưng thật ra là nguyên con rất nhìu chỉ vs 50k các loại nước uống cũng dc tính vs giá bình dân', 'thấy review tốt nên noel mình đưa gia đình đến thử có vẻ quán chỉ phục vụ tốt khi vắng khách đông khách một tí là nhân viên chạy loạn cào cào order món ăn nửa tiếng sau chẳng thấy đâu hỏi thì cứ ừ hử rồi vẫn chẳng đâu vào đâu hứa với lòng ko quay lại lần nào nữa', 'thích bánh tráng bơ bánh tráng trộn bình thường giá ổn chỗ ngồi ít làm khá lâu phục vụ bình thường', 'quán decor đẹp địa điểm đẹp đồ ăn ngon hợp khẩu vị mình rất kết món chè mít mã thầy và xôi sầu riêng tuy nhiên âm thanh trong quan chưa được tốt không gian đẹp mà nhạc thì bật lẩu thập cẩm các thể loại không liên quan lắm nói chung là rất hài lòng về đồ ăn và không gian sugest các bạn tới ăn vặt ăn tráng miệng', 'lẩu cua tại đây tuy giá hơi đắt nhưng ăn rất ngon nước dùng nấu đậm đà cùng với đậu phụ tôm cua rất tươi ăn một lần sẽ nhớ mãi hương vị không quán nào sánh bằng ngoài ra còn có món bò bóp thấu khá ngon không gian quán rộng rãi phù hợp đi gia đình tụ tập bạn bè', 'điều hoà mát không gian đẹp nhân viên xinh xắn nhiệt tình lại có hệ thống wifi xịn vãi mỗi tội không có gấu dẫn đi nên bình thường chẳng khoái'), tensor([1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1])]\n"]}]},{"cell_type":"code","metadata":{"id":"jJc7Ez9lFxQl"},"source":["# !!git clone https://github.com/pytorch/fairseq\n","# %cd /content/fairseq/\n","# !python -m pip install --editable .\n","# python setup.py build_ext --inplace\n","# %cd /content"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gJjb04m0nGBX"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"laCD7EF5PZnz"},"source":["from fairseq.data import Dictionary\n","import sentencepiece as spm\n","from os.path import join as pjoin\n","from transformers import PreTrainedTokenizer\n","import sentencepiece as spm\n","\n","class XLMRobertaTokenizer(PreTrainedTokenizer):\n","    def __init__(\n","        self,\n","        pretrained_file,\n","        bos_token=\"<s>\",\n","        eos_token=\"</s>\",\n","        sep_token=\"</s>\",\n","        cls_token=\"<s>\",\n","        unk_token=\"<unk>\",\n","        pad_token=\"<pad>\",\n","        mask_token=\"<mask>\",\n","        **kwargs\n","    ):\n","        super().__init__(\n","            bos_token=bos_token,\n","            eos_token=eos_token,\n","            unk_token=unk_token,\n","            sep_token=sep_token,\n","            cls_token=cls_token,\n","            pad_token=pad_token,\n","            mask_token=mask_token,\n","            **kwargs,\n","        )\n","        # load bpe model and vocab file\n","        sentencepiece_model = pjoin(pretrained_file, 'sentencepiece.bpe.model')\n","        vocab_file = pjoin(pretrained_file, 'dict.txt')\n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(sentencepiece_model)   # please dont use anything from sp_model bcz it makes everything goes wrong\n","        self.bpe_dict = Dictionary().load(vocab_file)\n","        # Mimic fairseq token-to-id alignment for the first 4 token\n","        self.fairseq_tokens_to_ids = {\"<s>\": 0, \"<pad>\": 1, \"</s>\": 2, \"<unk>\": 3}\n","        # The first \"real\" token \",\" has position 4 in the original fairseq vocab and position 3 in the spm vocab\n","        self.fairseq_offset = 0\n","        self.fairseq_tokens_to_ids[\"<mask>\"] = len(self.bpe_dict) + self.fairseq_offset\n","        self.fairseq_ids_to_tokens = {v: k for k, v in self.fairseq_tokens_to_ids.items()}\n","     \n","    def _tokenize(self, text): \n","        return self.sp_model.EncodeAsPieces(text)\n","\n","    def _convert_token_to_id(self, token):\n","        \"\"\" Converts a token (str) in an id using the vocab. \"\"\"\n","        if token in self.fairseq_tokens_to_ids:\n","            return self.fairseq_tokens_to_ids[token]\n","        spm_id = self.bpe_dict.index(token)\n","        return spm_id\n","\n","    def _convert_id_to_token(self, index):\n","        \"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"\n","        if index in self.fairseq_ids_to_tokens:\n","            return self.fairseq_ids_to_tokens[index]\n","        return self.bpe_dict[index]\n","\n","    @property\n","    def vocab_size(self):\n","        return len(self.bpe_dict) + self.fairseq_offset + 1  # Add the <mask> token\n","\n","    def get_vocab(self):\n","        vocab = {self.convert_ids_to_tokens(i): i for i in range(self.vocab_size)}\n","        vocab.update(self.added_tokens_encoder)\n","        return vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sypO4qMvnwOL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636626242380,"user_tz":-420,"elapsed":5315,"user":{"displayName":"19021256 Hà Đông Giang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gja8sSUuDXalRZWbplQyuJDwBAfSe11LPI2D-Ebjw=s64","userId":"04530108174427629943"}},"outputId":"3e26a51f-3bfb-4a8d-ea81-4dadf62c3888"},"source":["from transformers import XLMRobertaConfig, XLMRobertaForSequenceClassification\n","import torch\n","\n","pretrained_path = '/content/drive/MyDrive/programming/nlp/pretrained/envibert/'\n","!ls $pretrained_path\n","\n","roberta = XLMRobertaForSequenceClassification.from_pretrained(pretrained_path)\n","tokenizer = XLMRobertaTokenizer(pretrained_path)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["config.json  dict.txt  model.pt  pytorch_model.bin  sentencepiece.bpe.model\n"]},{"output_type":"stream","name":"stderr","text":["You are using a model of type roberta to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at /content/drive/MyDrive/programming/nlp/pretrained/envibert/ were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/programming/nlp/pretrained/envibert/ and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"id":"g8mZiHH8yltU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636626243093,"user_tz":-420,"elapsed":740,"user":{"displayName":"19021256 Hà Đông Giang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gja8sSUuDXalRZWbplQyuJDwBAfSe11LPI2D-Ebjw=s64","userId":"04530108174427629943"}},"outputId":"387dea10-08f9-40fb-8131-8e4885d0ff42"},"source":["inputs = [\"Tôi ghét nó\", \"Tôi thích nó\", \"Tôi quý nó\"]\n","inputs = tokenizer(inputs, return_tensors='pt')\n","print(inputs)\n","outputs = roberta(**inputs, labels=torch.tensor([0, 1, 1]))\n","print(outputs)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[ 842, 8919,  543],\n","        [ 842,  648,  543],\n","        [ 842,  976,  543]]), 'token_type_ids': tensor([[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1],\n","        [1, 1, 1],\n","        [1, 1, 1]])}\n","SequenceClassifierOutput(loss=tensor(0.6879, grad_fn=<NllLossBackward>), logits=tensor([[-0.0371,  0.0014],\n","        [-0.0387, -0.0014],\n","        [-0.0375, -0.0037]], grad_fn=<AddmmBackward>), hidden_states=(tensor([[[-5.0629e-02, -1.3749e-01, -1.0452e-01,  ..., -5.6184e-03,\n","           7.6252e-02, -7.4683e-02],\n","         [-5.0720e-02, -1.9042e-01, -2.5382e-01,  ..., -2.4447e-01,\n","          -9.7407e-02, -1.1625e-02],\n","         [ 2.4340e-01, -7.1564e-02,  2.5017e-01,  ..., -2.3644e-01,\n","           1.2962e-01,  2.3541e-01]],\n","\n","        [[-5.0629e-02, -1.3749e-01, -1.0452e-01,  ..., -5.6184e-03,\n","           7.6252e-02, -7.4683e-02],\n","         [ 1.0403e-01, -1.9165e-01, -5.2380e-01,  ..., -2.7758e-01,\n","          -1.0180e-01, -4.1142e-02],\n","         [ 2.4340e-01, -7.1564e-02,  2.5017e-01,  ..., -2.3644e-01,\n","           1.2962e-01,  2.3541e-01]],\n","\n","        [[-5.0629e-02, -1.3749e-01, -1.0452e-01,  ..., -5.6184e-03,\n","           7.6252e-02, -7.4683e-02],\n","         [ 3.1209e-01, -1.8171e-01,  5.8553e-02,  ..., -2.9276e-01,\n","          -4.6882e-04,  2.1470e-02],\n","         [ 2.4340e-01, -7.1564e-02,  2.5017e-01,  ..., -2.3644e-01,\n","           1.2962e-01,  2.3541e-01]]], grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.0063,  0.0700, -0.0074,  ...,  0.0706, -0.0076,  0.1507],\n","         [ 0.0512, -0.1514, -0.4457,  ...,  0.1985, -0.0218,  0.0303],\n","         [ 0.2963,  0.0676,  0.1520,  ...,  0.2284,  0.1074,  0.4440]],\n","\n","        [[ 0.0038,  0.0702, -0.0047,  ...,  0.0653, -0.0067,  0.1484],\n","         [ 0.2337,  0.0375, -0.3357,  ...,  0.1220, -0.1495,  0.0903],\n","         [ 0.2010,  0.1822,  0.1906,  ...,  0.2233,  0.1520,  0.4716]],\n","\n","        [[-0.0024,  0.0661, -0.0079,  ...,  0.0596,  0.0009,  0.1326],\n","         [ 0.4062, -0.0347, -0.1867,  ...,  0.2045,  0.0717,  0.0288],\n","         [ 0.1537,  0.0752,  0.1466,  ...,  0.2389,  0.2358,  0.3372]]],\n","       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.0795, -0.0390, -0.0363,  ..., -0.0323, -0.0568,  0.4800],\n","         [-0.0275, -0.1309, -0.5121,  ...,  0.1883, -0.0999, -0.0762],\n","         [ 0.5632, -0.0018,  0.0218,  ...,  0.0682,  0.2403,  0.5810]],\n","\n","        [[-0.0914, -0.0780, -0.0391,  ..., -0.0145, -0.0477,  0.4544],\n","         [ 0.2112, -0.1623, -0.3518,  ...,  0.0401, -0.2851,  0.0503],\n","         [ 0.4142, -0.0935,  0.1026,  ...,  0.0499,  0.2110,  0.6388]],\n","\n","        [[-0.0945, -0.1406, -0.0251,  ..., -0.0125, -0.0535,  0.3862],\n","         [ 0.2984, -0.2297, -0.3045,  ...,  0.1922, -0.0698,  0.0031],\n","         [ 0.2133, -0.0253,  0.0393,  ...,  0.1223,  0.3713,  0.5427]]],\n","       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.0952, -0.4132, -0.2270,  ..., -0.2418, -0.1055,  0.6953],\n","         [ 0.0552,  0.1798, -0.2839,  ...,  0.0342, -0.1148, -0.2086],\n","         [ 0.4718, -0.1813,  0.2222,  ...,  0.4447,  0.1647,  0.5643]],\n","\n","        [[-0.0775, -0.4988, -0.3397,  ..., -0.2402, -0.1574,  0.7216],\n","         [ 0.1022, -0.0646, -0.1252,  ...,  0.1196, -0.1493, -0.0454],\n","         [ 0.3883, -0.2784,  0.3078,  ...,  0.5586,  0.1749,  0.5589]],\n","\n","        [[-0.1590, -0.4940, -0.3847,  ..., -0.2620, -0.1822,  0.7346],\n","         [ 0.1928, -0.2468,  0.0842,  ...,  0.3488, -0.1687, -0.0081],\n","         [ 0.1982, -0.2828,  0.2641,  ...,  0.5723,  0.3457,  0.5481]]],\n","       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.0487, -0.0501,  0.0937,  ...,  0.0387,  0.0125,  0.1947],\n","         [-0.4098, -0.7699, -0.2643,  ..., -0.4536,  0.3037, -0.2623],\n","         [-0.2778, -0.7241,  0.0420,  ..., -0.3849,  0.5268, -0.0353]],\n","\n","        [[-0.0600, -0.0464,  0.0665,  ..., -0.0311,  0.0312,  0.1913],\n","         [-0.4751, -0.8494, -0.0786,  ..., -0.2642,  0.3250, -0.2619],\n","         [-0.3564, -0.7230,  0.0074,  ..., -0.2563,  0.5192, -0.1212]],\n","\n","        [[-0.1734, -0.0279,  0.0133,  ..., -0.0913,  0.0524,  0.2820],\n","         [-0.4592, -0.9239, -0.0584,  ..., -0.4687,  0.3391, -0.3225],\n","         [-0.4737, -0.8135,  0.0289,  ..., -0.3745,  0.6057, -0.1639]]],\n","       grad_fn=<NativeLayerNormBackward>), tensor([[[-6.0601e-02, -5.4100e-02,  3.1829e-02,  ...,  3.5685e-02,\n","           7.1350e-03,  2.3746e-02],\n","         [-4.0451e-01, -1.6697e-01, -4.6691e-01,  ..., -5.0639e-01,\n","           6.5037e-01, -1.5655e-01],\n","         [-3.1407e-01, -2.5777e-01, -2.0799e-01,  ..., -4.2114e-01,\n","           6.7328e-01, -1.5112e-02]],\n","\n","        [[-5.1821e-02, -6.0576e-02,  2.6850e-02,  ...,  5.1314e-02,\n","           2.6790e-03, -6.2144e-04],\n","         [-4.6940e-01, -2.3216e-01, -3.3027e-01,  ..., -2.3653e-01,\n","           5.7389e-01, -2.9652e-01],\n","         [-4.0736e-01, -1.8571e-01, -2.4843e-01,  ..., -2.5586e-01,\n","           6.8625e-01, -2.0028e-01]],\n","\n","        [[-4.6912e-02, -4.5773e-02,  1.3105e-02,  ...,  2.7113e-02,\n","          -8.0170e-03, -2.8805e-03],\n","         [-3.6418e-01, -1.9414e-01, -3.4840e-01,  ..., -3.8341e-01,\n","           4.7391e-01, -2.2463e-01],\n","         [-3.7984e-01, -1.7496e-01, -2.3391e-01,  ..., -3.0434e-01,\n","           4.6656e-01, -1.2788e-01]]], grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.1223, -0.1486, -0.1789,  ...,  0.0779,  0.0374, -0.2220],\n","         [-0.1269, -0.1616, -0.2433,  ..., -0.0898,  0.1405, -0.0112],\n","         [-0.0972, -0.1811, -0.1392,  ..., -0.0584,  0.2059,  0.0435]],\n","\n","        [[ 0.1421, -0.1630, -0.1701,  ...,  0.1001,  0.0491, -0.2693],\n","         [-0.1609, -0.2084, -0.1999,  ...,  0.0148,  0.1193, -0.1326],\n","         [-0.1364, -0.1846, -0.1470,  ..., -0.0006,  0.1701, -0.0665]],\n","\n","        [[ 0.1022, -0.2458, -0.1111,  ...,  0.0420,  0.0375, -0.2566],\n","         [-0.1660, -0.2209, -0.1548,  ..., -0.0330,  0.1422, -0.1152],\n","         [-0.1861, -0.2228, -0.0459,  ..., -0.0517,  0.1614, -0.0745]]],\n","       grad_fn=<NativeLayerNormBackward>)), attentions=None)\n"]}]},{"cell_type":"code","metadata":{"id":"GW03BijknFFb"},"source":["from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n","\n","class SentimentRoberta(pl.LightningModule):\n","  def __init__(self, lr_roberta, lr_classifier):\n","    super().__init__()\n","    self.roberta = XLMRobertaForSequenceClassification.from_pretrained(pretrained_path)\n","    self.tokenizer = XLMRobertaTokenizer(pretrained_path)\n","    self.lr_roberta = lr_roberta\n","    self.lr_classifer = lr_classifier\n","\n","\n","  def forward(self, texts, labels=None):\n","    inputs = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=256)\n","    for key in inputs:\n","      inputs[key] = inputs[key].to(self.device)\n","\n","    outputs = self.roberta(**inputs, labels=labels)\n","    return outputs\n","\n","\n","  def configure_optimizers(self):\n","    roberta_params = self.roberta.roberta.named_parameters()\n","    classifier_params = self.roberta.classifier.named_parameters()\n","\n","    grouped_params = [\n","      {\"params\": [p for n, p in roberta_params], \"lr\": self.lr_roberta},\n","      {\"params\": [p for n, p in classifier_params], \"lr\": self.lr_classifer}\n","    ]\n","    optimizer = torch.optim.AdamW(\n","        grouped_params\n","    )\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.98)\n","    return {\n","        'optimizer': optimizer,\n","        'lr_scheduler': {\n","            'scheduler': scheduler,\n","            'monitor': 'f1/val',\n","        }\n","    }\n","\n","  def training_step(self, batch, batch_idx):\n","    texts, labels = batch\n","    outputs = self(texts, labels=labels)\n","\n","    if len(outputs.values()) == 3:\n","      loss, logits, _ = outputs.values()\n","    else:\n","      loss, logits = outputs.values()\n","    return loss\n","\n","  def validation_step(self, batch, batch_idx):\n","    texts, labels = batch\n","    outputs = self(texts, labels=labels)\n","\n","    if len(outputs.values()) == 3:\n","      loss, logits, _ = outputs.values()\n","    else:\n","      loss, logits = outputs.values()\n","\n","    output_scores = torch.softmax(logits, dim=-1)\n","    return loss, output_scores, labels\n","\n","  def validation_epoch_end(self, validation_step_outputs):\n","\n","    val_preds = torch.tensor([], device=self.device)\n","    val_scores = torch.tensor([], device=self.device)\n","    val_labels = torch.tensor([], device=self.device)\n","    val_loss = 0\n","    total_item = 0\n","\n","    for idx, item in enumerate(validation_step_outputs):\n","      loss, output_scores, labels = item\n","\n","      predictions = torch.argmax(output_scores, dim=-1)\n","      val_preds = torch.cat((val_preds, predictions), dim=0)\n","      val_scores = torch.cat((val_scores, output_scores[:,1]), dim=0)\n","      val_labels = torch.cat((val_labels, labels), dim=0)\n","\n","      val_loss += loss\n","      total_item += 1\n","\n","    # print(\"VAL PREDS\", val_preds.shape)\n","    # print(\"VAL SCORES\", val_scores.shape)\n","    # print(\"VAL LABELS\", val_labels.shape)\n","    val_preds = val_preds.cpu().numpy()\n","    val_scores = val_scores.cpu().numpy()\n","    val_labels = val_labels.cpu().numpy()\n","    \n","    reports = classification_report(val_labels, val_preds, output_dict=True)\n","    print(\"VAL LABELS\", val_labels)\n","    print(\"VAL SCORES\", val_scores)\n","    try:\n","      auc = roc_auc_score(val_labels, val_scores)\n","    except Exception as e:\n","      print(e)\n","      print(\"Cannot calculate AUC. Default to 0\")\n","      auc = 0\n","    accuracy = accuracy_score(val_labels, val_preds)\n","\n","    print(classification_report(val_labels, val_preds))\n","\n","    self.log(\"loss/val\", val_loss)\n","    self.log(\"auc/val\", auc)\n","    self.log(\"accuracy/val\", accuracy)\n","    self.log(\"precision/val\", reports[\"weighted avg\"][\"precision\"])\n","    self.log(\"recall/val\", reports[\"weighted avg\"][\"recall\"])\n","    self.log(\"f1/val\", reports[\"weighted avg\"][\"f1-score\"])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qMRyo5iYBvn8","colab":{"base_uri":"https://localhost:8080/","height":834,"referenced_widgets":["187ff8cf813f409383dc9419d289fb5f","fa3b7f2511454424b2d1f50e5b193766","3edb969a48064cfb9f72148f13ccca48","b56e6541a1cc4873b50ea780a5802591","220de73859004c788efc7c3f6ae6ffc0","9fd708e08caa4f74ac4b6be6bc1bb82a","b8d3a32d6768434988685192333ec147","634100632cf447b380c5f4186f782538","807a370805e140cdb04eee9f184de0da","073be319d4da4369916614eb9187dec3","492036cc591b447cb6b42b8a87c5c2aa","02b053738937420e92d609faeab512fc","f67f4fb024e8443bbd3087a2ebbc5b61","a923349caf2b47cf96acaf440c259041","a621a93ceb0e4cebb69fa0cae10ec4eb","580065394c3d4aedbd2003e05618f98c","dc27247c51994fcf9039b9a5cdbfeb7d","a585967c728748568fe269a7bc74d7b6","4f13b487b2c64fe99422d84cbea0f272","21dda556134d4c03a9cb7fa9f014632e","8051f7a94d574c7da0823c200f38b225","6845c913925d4d8594b15b463a5177a7"]},"executionInfo":{"status":"ok","timestamp":1636626260097,"user_tz":-420,"elapsed":17017,"user":{"displayName":"19021256 Hà Đông Giang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gja8sSUuDXalRZWbplQyuJDwBAfSe11LPI2D-Ebjw=s64","userId":"04530108174427629943"}},"outputId":"c73d138c-4a13-4668-eec0-652bd0249553"},"source":["trainer = pl.Trainer(\n","    fast_dev_run=True,\n",")\n","model = SentimentRoberta(lr_roberta=1e-5, lr_classifier=3e-3)\n","dm = SentimentDataModule()\n","\n","trainer.fit(model, dm)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["GPU available: True, used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:1567: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n","  \"GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\"\n","Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n","You are using a model of type roberta to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at /content/drive/MyDrive/programming/nlp/pretrained/envibert/ were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/programming/nlp/pretrained/envibert/ and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","  | Name    | Type                                | Params\n","----------------------------------------------------------------\n","0 | roberta | XLMRobertaForSequenceClassification | 70.7 M\n","----------------------------------------------------------------\n","70.7 M    Trainable params\n","0         Non-trainable params\n","70.7 M    Total params\n","282.818   Total estimated model params size (MB)\n"]},{"output_type":"stream","name":"stdout","text":["27000 21600 5400\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:395: UserWarning: The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"187ff8cf813f409383dc9419d289fb5f","version_minor":0,"version_major":2},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 959. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02b053738937420e92d609faeab512fc","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 547. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"output_type":"stream","name":"stdout","text":["VAL LABELS [1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1.]\n","VAL SCORES [0.11248375 0.14095211 0.09060212 0.13426316 0.14714074 0.095732\n"," 0.09746041 0.1130011  0.11765185 0.10690454 0.13107814 0.12104373\n"," 0.14510155 0.07852908 0.09756076 0.1506509 ]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.44      1.00      0.61         7\n","         1.0       0.00      0.00      0.00         9\n","\n","    accuracy                           0.44        16\n","   macro avg       0.22      0.50      0.30        16\n","weighted avg       0.19      0.44      0.27        16\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","metadata":{"id":"0HtXPhT4g9VN"},"source":["# Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a5bfc7cb5bd645a1bc2e9313d2101dd2","3e973a04cd814ff18739a5fd8ddc699a","9e7d33b23f4d42eb93fe174cf2af3453","8955877c902b44e9a35694fc2f234fbc","8e76dd3f3ede4727ae082fb2e91c9948","a60b8dd809b14a4d85ad41eaa91fb509","d8ae352ea3384079a224d9c447b32431","2e8df380f56244178cf0ddc2dddc9f3b","558d92c75cd64664890305c515e62389","4dfa97007ad840af8aead701031322c0","f00847f053794341ac613797696c576b","cc51334b15514b02a15670f7befa7d56","7e39d85b5f8c459ca5241bceca77fd66","cd10c98aa74e49e0aa8aea58e87bc998","ce3d4395812f446cb9f1bcd0ce6f769b","ce5c6701885745bd9f7e0f5ff7d50994","b7067c72d03748eb8e0ebfc7a2af82b8","4d0af1ee648146b4a69caf7a12ce1d0e","f4300b0c2f2d451ca17418cd4321d4b8","3f07d82072c34fffb58cc514897d6d06","fd2226c561c94049bfe095a7fde810a7","69aaffdd11c045d188b208f2dc86bbe6","1260c4a7d0fd40dabe89d2efd4b90924","636177abb60546f3921025b80ea37f06","5787a3b635e54f12bab9efc3511f2dd4","82210154e22647fc93138392f0a5a1a7","0d18e1a3a5dc4988aed08b0324134641","11bfcdb589204efa92395ae4d452fdab","1fdbe635aeb5406896312e1dec9e7174","bb3d74ec597e4e96a71a83417d8bf4b6","ab12e5d69eec466fa02758a51ca23f40","43cd1fad28244a4ab675bc6e2a4cf708","ccd1d1dd6d1e46b2b99f143aae378847","065e68cad9854b348b67ef939d0bcafd","3428fe23f79244558619570a83099c59","1db36b299f6940c1ad31fc109d5876cb","d693547b0e614648b691af41bb160265","474e2114c306478297fc756e1d51ad35","2f7f8e5765444e4c833084897765c6cb","25da9df499344d2bbf2d161f1e5e960e","ee020b0333244c2290e441754bd083cb","4cb4f2ec10fa41e0a285b00c78461a34","d9a2f73080044233b71e76878354b370","efad8ed4c356462992df6b0d5b61ea3d","6c96502cbd8242099c7d4540a29099e3","124ae2fd6e994c69ac31fbc3b643bc77","1512fa40d5284773aea5eb7870144f7f","90707f73f2ea4e4b844d21def6b18a0c","55bee780013041d88443cfddbc365e0f","7dbfb7a63761415e819ae435a943c9bb","bbe639e8ce844ccbafe164ca0f6c07ef","0feeea6de748413db11852be28d9821f","bc18deaa9b144218a191437b7739346c","0ea8439ae165495783bb1e9a12c3ad7b","bfd219e042e04de2898015d57f072e4b","589ce4b9ec8a4832b0b23ee312fd6d90","2c36f62e4b6446a4be77d2015231d899","fa43ef9b22ff465188d5791fca172568","435c2bac57b1467b92432f4b32669f71","3b5426e1d8ee494dbeae33392de19f13","ae83e83933134135954fb22d890d963d","500732b0428f4697903e44019f193e86","f211e9d2a18949c1945d26d4a2a00d3f","89e6aa53170c426387e2548d4ca3a2bc","bd1405cbed0b42d1bdab92ed1ff04c79","daa7278e42fd4243972a11b368a940be","5611a00c21a842d1b21e238f8aa2e495","afcbf53ffb2847ff8f2cd34648a3ba4d","8a0cf7c5e5c642a785d329e38875b8e7","6e2e43ebb08844608a9a0a5645cc6cf4","1073143fe61e4761a744d49a996b80d5","49a04245cb62432aac898d5c58153210","f712795aaa614ef98355023f07cf204c","684f762194a2418181e09ea7fef7d62a","7e122750287945a8b895e9812075ce20","61a0417cebfe4ef6b64caee15983209e","dbd2681c21254b09bce79054a41a12ed","b4db087b10e049fbbc9436fabf77d37e","dd8a73c059e6428d80e0734b8a82aff4","add6c226c5ee493293c17f58ceb14fd4","fe181e62beb24f16ab54202c8a3e53cf","17f9afed3f6c4fdbbfa25b00689cbcda","d94ec2f07fbd4475a7054b07996abb6c","8e71e6e50a66457e8c24f836127bef11","b8ef787141c2487986a34aefe659a7d0","4c1d22e7b4cb4186a7fc26d0957370ba","94ea8fc5fffe46e6b215e64da7abb4ea","4a456d587f6b4961aa4e448d402cab4f","d39e21d88b364c0ea8b1ec86d7602527","0fb031d06a6446fba8b897bb86b48fa4","18350d4e2e414097bd87c466e1ac3f32","1e6b9d6ac7e64e7ebc3189a0b71bcda6","94aa377685624923a995e9fdab4612e8","260121785a844a3282dad7cebaa7c75e","23b582dca6794efab3fd0451abedb24a","59c1adbc66784a87b0071276d71466ed","27c1291be5d64d52b6cced79e3119965","dc50a6ab1fba4917aa33aae4315eb4ba","7f93c76a5c1348e6ad8736bf391e5a05"]},"id":"BfhWop6-hD08","executionInfo":{"status":"ok","timestamp":1636630555939,"user_tz":-420,"elapsed":4295858,"user":{"displayName":"19021256 Hà Đông Giang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gja8sSUuDXalRZWbplQyuJDwBAfSe11LPI2D-Ebjw=s64","userId":"04530108174427629943"}},"outputId":"9e90ba5a-5cbb-425b-9ef9-77f0523255bf"},"source":["from pytorch_lightning import loggers as pl_loggers\n","from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n","\n","torch.manual_seed(123)\n","\n","tb_logger = pl_loggers.TensorBoardLogger('/content/drive/MyDrive/colab/tb_logs/')\n","\n","trainer = pl.Trainer(\n","    min_epochs=1,\n","    max_epochs=5,\n","    gpus=1,\n","    precision=16,\n","    val_check_interval=0.5,\n","    # check_val_every_n_epoch=1,\n","    callbacks=[\n","      ModelCheckpoint(\n","          dirpath='/content/drive/MyDrive/ckpt',\n","          save_top_k=3,\n","          monitor='f1/val',\n","      ), \n","      EarlyStopping('f1/val', patience=5)\n","    ],\n","    fast_dev_run=False,\n","    logger=tb_logger\n",")\n","\n","dm.setup(stage=\"fit\")\n","trainer.fit(model, dm)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using 16bit native Automatic Mixed Precision (AMP)\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:470: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n","  f\"DataModule.{name} has already been called, so it will not be called again. \"\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name    | Type                                | Params\n","----------------------------------------------------------------\n","0 | roberta | XLMRobertaForSequenceClassification | 70.7 M\n","----------------------------------------------------------------\n","70.7 M    Trainable params\n","0         Non-trainable params\n","70.7 M    Total params\n","141.409   Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/ckpt exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5bfc7cb5bd645a1bc2e9313d2101dd2","version_minor":0,"version_major":2},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 348. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["VAL LABELS [1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n"," 1. 1. 0. 1. 1. 1. 0. 0.]\n","VAL SCORES [0.1124538  0.14098547 0.09057447 0.13437785 0.14718705 0.09577148\n"," 0.09756223 0.11284428 0.1176228  0.10697014 0.13106197 0.12111288\n"," 0.1450548  0.07850098 0.09756223 0.15065254 0.15533455 0.09268778\n"," 0.1127954  0.10622612 0.09773432 0.12683924 0.10194652 0.08632348\n"," 0.08701921 0.15065254 0.18308188 0.09442688 0.08866235 0.13039611\n"," 0.12080135 0.13609089]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.41      1.00      0.58        13\n","         1.0       0.00      0.00      0.00        19\n","\n","    accuracy                           0.41        32\n","   macro avg       0.20      0.50      0.29        32\n","weighted avg       0.17      0.41      0.23        32\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc51334b15514b02a15670f7befa7d56","version_minor":0,"version_major":2},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 550. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 434. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 464. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 125. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 69. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 303. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1338. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 267. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 146. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 174. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 474. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 681. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 667. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 232. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 239. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 131. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 80. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 118. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1279. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 187. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 670. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 787. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 535. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 738. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 248. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 156. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 215. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 487. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 417. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1061. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 361. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 145. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 374. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1176. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 475. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 208. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 237. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 140. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 659. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1146. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 74. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 381. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 821. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 390. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 92. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 126. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 756. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 358. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 489. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 420. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 135. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 263. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 86. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 90. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1330. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 130. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 596. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 462. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 216. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 365. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 436. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 159. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 151. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 504. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 403. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 423. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 227. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 180. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 640. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 58. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 368. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 144. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 161. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 320. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 240. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 531. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 289. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 154. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 845. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 364. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 360. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 600. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 268. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 713. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 292. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 493. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 450. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 106. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 143. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 378. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 485. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 155. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 285. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 594. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 88. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 288. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 111. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 241. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 627. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 179. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 221. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 700. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1105. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 170. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 412. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 409. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 383. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 157. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 356. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 521. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 202. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 334. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 957. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 211. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 137. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 164. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 326. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 56. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 321. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 629. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 305. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 70. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 574. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 311. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 171. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 556. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 257. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 191. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 97. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 120. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 425. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 85. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 189. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 116. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 818. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 349. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 262. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 141. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1066. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 48. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 655. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 441. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1391. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 245. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 182. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 207. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 472. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 247. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 251. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 162. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 443. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 136. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 149. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 329. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1166. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 621. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 252. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 104. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 491. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 222. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 134. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 95. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 316. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1071. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 84. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 101. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 115. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 67. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 561. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 435. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 290. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 388. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 418. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 597. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 658. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 235. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 469. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 327. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 253. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 580. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 226. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 529. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1068. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 230. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 114. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 426. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 82. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 61. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 494. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 209. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 446. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 219. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 244. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 53. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 78. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 649. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 527. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 537. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 440. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 466. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 386. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 722. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 249. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 523. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 225. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 133. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 682. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 192. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 601. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 572. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 525. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 445. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 838. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1026. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 437. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 398. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 498. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 820. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 105. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 307. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 160. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 638. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 641. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 647. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 429. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 505. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 751. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 399. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 346. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 102. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 915. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 345. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 72. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 177. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 340. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 196. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 229. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 96. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 264. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 455. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 402. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 513. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 336. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 175. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 121. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 73. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 812. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 128. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 129. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 416. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 110. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 363. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 609. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 811. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 279. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 544. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 199. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1334. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 611. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 456. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 113. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1722. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 827. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 486. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 902. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 109. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 272. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 203. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 220. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 530. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 75. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 571. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 194. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 59. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 98. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 250. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 153. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 266. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 223. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1099. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 273. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 163. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 488. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 506. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 645. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 366. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 772. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1669. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1145. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 552. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 577. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 385. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1106. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 331. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1635. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 193. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 100. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 234. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 896. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 780. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 568. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 325. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 271. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1164. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 322. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 167. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 165. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 66. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 424. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 265. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 259. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 83. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 555. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 632. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1331. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 176. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1148. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 953. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 376. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 52. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 613. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 172. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 620. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 554. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 846. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 924. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 439. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 852. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1138. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 719. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2291. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 520. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 152. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 449. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 132. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 246. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 79. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 790. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 422. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 238. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 419. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 139. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 68. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 698. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 379. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 173. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 343. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 524. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 166. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 205. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 470. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 124. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 740. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 150. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 389. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 373. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 103. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 610. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 123. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 644. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 980. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 593. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 686. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 581. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 297. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 122. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 243. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 457. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 478. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 730. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1269. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1683. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 315. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 117. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 255. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 353. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 254. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 467. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 350. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 962. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1970. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 553. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 184. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 518. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 393. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 99. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 522. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 47. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 741. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 511. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 65. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 569. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 680. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 636. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 792. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 77. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 185. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 691. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 433. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 206. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 517. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 93. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 872. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 411. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 507. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 183. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 587. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 312. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 854. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 228. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 224. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 696. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 256. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1508. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 258. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 213. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 112. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 355. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 623. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 201. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 89. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 188. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 481. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1260c4a7d0fd40dabe89d2efd4b90924","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1404. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 413. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 979. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 624. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 497. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 76. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 822. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 565. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 40. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 278. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 453. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 384. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 541. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 606. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 351. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 823. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1242. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 142. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 883. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 452. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 391. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1240. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1154. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1747. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 567. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 582. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 512. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 408. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 401. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 448. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 766. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 490. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 280. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 886. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 684. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 198. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 204. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 841. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 261. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 473. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 218. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 168. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 231. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1623. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 771. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 357. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1123. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 590. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1018. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 598. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 548. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 612. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 496. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1102. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 484. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1244. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1688. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 45. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 341. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 63. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 759. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 508. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 236. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 729. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 392. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1489. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 51. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 200. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1031. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 62. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 338. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 851. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 563. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 689. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 809. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 575. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 354. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 816. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 210. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 127. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 545. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 716. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 903. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 558. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 814. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 532. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1092. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 197. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 747. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 584. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 81. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 961. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 158. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 427. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 755. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 808. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1395. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 276. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 622. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1015. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1905. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 671. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 332. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 468. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 87. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"output_type":"stream","name":"stdout","text":["VAL LABELS [1. 1. 0. ... 1. 1. 1.]\n","VAL SCORES [0.8329853  0.9756467  0.37337586 ... 0.99227446 0.98792297 0.9700703 ]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.84      0.89      2654\n","         1.0       0.86      0.95      0.90      2746\n","\n","    accuracy                           0.89      5400\n","   macro avg       0.90      0.89      0.89      5400\n","weighted avg       0.90      0.89      0.89      5400\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1585. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2490. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 333. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 893. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1117. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 377. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 585. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 260. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1473. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 796. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 107. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 695. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 510. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 750. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 274. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 138. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 217. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1226. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1712. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 148. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 677. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 791. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1070. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 794. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1386. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2352. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 859. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1032. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 708. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 825. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 190. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 748. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 869. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 283. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 526. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 71. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 492. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 375. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 195. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 662. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 181. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 344. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 630. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 447. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 328. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 60. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1345. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 369. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 287. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 539. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 178. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 562. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 576. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1114. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1033. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 57. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 42. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 479. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 458. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 147. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 546. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 856. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 186. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1024. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 395. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 352. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 212. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2091. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1270. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 842. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1513. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1837. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 275. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 735. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 666. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1050. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 476. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 705. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 826. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 930. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 911. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 783. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1644. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 885. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 49. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 877. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 54. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 482. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1186. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 499. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 428. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 628. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1073. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 949. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 502. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1308. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 866. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 444. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1227. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1147. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 477. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 503. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1037. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 551. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 654. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 242. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 988. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 438. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 359. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 763. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 633. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 828. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 773. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 592. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 367. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1140. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 430. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 591. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 46. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 495. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 404. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 813. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 768. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 269. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 996. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 394. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 734. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 933. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 777. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 969. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1350. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2485. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 798. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 978. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1662. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 540. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 371. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 752. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 387. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1180. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1617. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 564. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 119. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 760. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 347. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 998. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1238. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 91. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1076. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 669. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 595. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1046. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 560. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 214. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 762. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 849. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 865. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1751. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 668. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 534. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 639. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 284. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:57: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 460. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"065e68cad9854b348b67ef939d0bcafd","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["VAL LABELS [1. 1. 0. ... 1. 1. 1.]\n","VAL SCORES [0.9659959  0.9736447  0.9003547  ... 0.99454135 0.98680264 0.99532723]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.76      0.85      2654\n","         1.0       0.81      0.98      0.88      2746\n","\n","    accuracy                           0.87      5400\n","   macro avg       0.89      0.87      0.87      5400\n","weighted avg       0.89      0.87      0.87      5400\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c96502cbd8242099c7d4540a29099e3","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["VAL LABELS [1. 1. 0. ... 1. 1. 1.]\n","VAL SCORES [0.9296961  0.921499   0.6724393  ... 0.99329424 0.98546845 0.9680205 ]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.85      0.89      2654\n","         1.0       0.87      0.95      0.91      2746\n","\n","    accuracy                           0.90      5400\n","   macro avg       0.90      0.90      0.90      5400\n","weighted avg       0.90      0.90      0.90      5400\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"589ce4b9ec8a4832b0b23ee312fd6d90","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["VAL LABELS [1. 1. 0. ... 1. 1. 1.]\n","VAL SCORES [0.9874721  0.9706322  0.97313875 ... 0.9954704  0.9941801  0.9957353 ]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.79      0.87      2654\n","         1.0       0.83      0.97      0.89      2746\n","\n","    accuracy                           0.88      5400\n","   macro avg       0.90      0.88      0.88      5400\n","weighted avg       0.90      0.88      0.88      5400\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5611a00c21a842d1b21e238f8aa2e495","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["VAL LABELS [1. 1. 0. ... 1. 1. 1.]\n","VAL SCORES [0.96360916 0.9665687  0.8547634  ... 0.99583375 0.992725   0.96528316]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.83      0.89      2654\n","         1.0       0.85      0.96      0.90      2746\n","\n","    accuracy                           0.90      5400\n","   macro avg       0.90      0.90      0.90      5400\n","weighted avg       0.90      0.90      0.90      5400\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4db087b10e049fbbc9436fabf77d37e","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["VAL LABELS [1. 1. 0. ... 1. 1. 1.]\n","VAL SCORES [0.6376515  0.94402224 0.6559424  ... 0.9641868  0.9604726  0.9566342 ]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.85      0.90      2654\n","         1.0       0.87      0.96      0.91      2746\n","\n","    accuracy                           0.90      5400\n","   macro avg       0.91      0.90      0.90      5400\n","weighted avg       0.91      0.90      0.90      5400\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d39e21d88b364c0ea8b1ec86d7602527","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["VAL LABELS [1. 1. 0. ... 1. 1. 1.]\n","VAL SCORES [0.97879386 0.9685601  0.69014156 ... 0.9965436  0.9968149  0.9914391 ]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.83      0.89      2654\n","         1.0       0.85      0.97      0.91      2746\n","\n","    accuracy                           0.90      5400\n","   macro avg       0.91      0.90      0.90      5400\n","weighted avg       0.91      0.90      0.90      5400\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:470: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n","  f\"DataModule.{name} has already been called, so it will not be called again. \"\n"]}]},{"cell_type":"markdown","metadata":{"id":"L8wvJNe5xG62"},"source":["TEST"]},{"cell_type":"code","metadata":{"id":"Qo1gSkpVxO80"},"source":["%reload_ext tensorboard\n","%tensorboard --logdir '/content/drive/MyDrive/colab/tb_logs/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKVQrC1TkzRG","executionInfo":{"status":"ok","timestamp":1636630566766,"user_tz":-420,"elapsed":13,"user":{"displayName":"19021256 Hà Đông Giang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gja8sSUuDXalRZWbplQyuJDwBAfSe11LPI2D-Ebjw=s64","userId":"04530108174427629943"}},"outputId":"883d0348-f94b-4410-bf48-3f8cfe7cd688"},"source":["inputs = [\"Món này ăn chán vậy\"]\n","outputs = model(inputs)\n","logits = outputs['logits']\n","score = torch.softmax(logits, dim=-1)\n","print(score)\n","print(torch.argmax(score, dim=-1).item())\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.8693, 0.1307]], grad_fn=<SoftmaxBackward>)\n","0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_GnkyPxg-02O","executionInfo":{"status":"ok","timestamp":1636634734546,"user_tz":-420,"elapsed":242875,"user":{"displayName":"19021256 Hà Đông Giang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gja8sSUuDXalRZWbplQyuJDwBAfSe11LPI2D-Ebjw=s64","userId":"04530108174427629943"}},"outputId":"9298d2ef-8514-4eff-f119-e101ee321c2d"},"source":["!tensorboard dev upload --logdir '/content/drive/MyDrive/colab/tb_logs/'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","***** TensorBoard Uploader *****\n","\n","This will upload your TensorBoard logs to https://tensorboard.dev/ from\n","the following directory:\n","\n","/content/drive/MyDrive/colab/tb_logs/\n","\n","This TensorBoard will be visible to everyone. Do not upload sensitive\n","data.\n","\n","Your use of this service is subject to Google's Terms of Service\n","<https://policies.google.com/terms> and Privacy Policy\n","<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n","<https://tensorboard.dev/policy/terms/>.\n","\n","This notice will not be shown again while you are logged into the uploader.\n","To log out, run `tensorboard dev auth revoke`.\n","\n","Continue? (yes/NO) yes\n","\n","Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=373649185512-8v619h5kft38l4456nm2dj4ubeqsrvh6.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&state=mWMILGxMaPys0LiDc2tsFTQdwBCzRH&prompt=consent&access_type=offline\n","Enter the authorization code: 4/1AX4XfWj9ylyaU_pUBLmYVYZmy0CkoPBBbLKrupwsfA8uWEqWJ7aZNejzAWM\n","\n","Upload started and will continue reading any new data as it's added to the logdir.\n","\n","To stop uploading, press Ctrl-C.\n","\n","New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/L2sbF0FaRyaG2qbvwpk5Tw/\n","\n","\u001b[1m[2021-11-11T12:42:07]\u001b[0m Started scanning logdir.\n","\u001b[1m[2021-11-11T12:42:07]\u001b[0m Total uploaded: 101 scalars, 9 tensors (54 B), 0 binary objects\n","\n","\n","Interrupted. View your TensorBoard at https://tensorboard.dev/experiment/L2sbF0FaRyaG2qbvwpk5Tw/\n"]}]}]}